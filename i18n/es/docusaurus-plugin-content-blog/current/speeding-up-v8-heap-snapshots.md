---
title: &apos;Acelerando las instant√°neas de mont√≥n de V8&apos;
description: &apos;Esta publicaci√≥n sobre instant√°neas de mont√≥n de V8 presenta algunos problemas de rendimiento encontrados por ingenieros de Bloomberg, y c√≥mo los solucionamos para que el an√°lisis de memoria de JavaScript sea m√°s r√°pido que nunca.&apos;
author: &apos;Jose Dapena Paz&apos;
date: 2023-07-27
tags:
 - memoria
 - herramientas
---
*Esta publicaci√≥n en el blog ha sido escrita por Jos√© Dapena Paz (Igalia), con contribuciones de Jason Williams (Bloomberg), Ashley Claymore (Bloomberg), Rob Palmer (Bloomberg), Joyee Cheung (Igalia) y Shu-yu Guo (Google).*

En esta publicaci√≥n sobre instant√°neas de mont√≥n de V8, hablar√© sobre algunos problemas de rendimiento encontrados por ingenieros de Bloomberg, y c√≥mo los solucionamos para que el an√°lisis de memoria de JavaScript sea m√°s r√°pido que nunca.

## El problema

Los ingenieros de Bloomberg estaban trabajando en diagnosticar una fuga de memoria en una aplicaci√≥n de JavaScript. Estaba fallando con errores de *Falta de Memoria*. Para la aplicaci√≥n probada, el l√≠mite del mont√≥n de V8 estaba configurado en aproximadamente 1400 MB. Normalmente, el colector de basura de V8 deber√≠a poder mantener el uso del mont√≥n por debajo de ese l√≠mite, por lo que los fallos indicaban que probablemente hab√≠a una fuga.

<!--truncate-->
Una t√©cnica com√∫n para depurar un escenario de fuga de memoria rutinario como este es capturar primero una instant√°nea de mont√≥n, luego cargarla en la pesta√±a ‚ÄúMemoria‚Äù de DevTools y averiguar qu√© est√° consumiendo m√°s memoria inspeccionando los distintos res√∫menes y atributos de los objetos. En la interfaz de DevTools, la instant√°nea de mont√≥n puede tomarse en la pesta√±a ‚ÄúMemoria‚Äù. Para aplicaciones de Node.js, la instant√°nea de mont√≥n [puede activarse program√°ticamente](https://nodejs.org/en/docs/guides/diagnostics/memory/using-heap-snapshot) utilizando esta API:

```js
require(&apos;v8&apos;).writeHeapSnapshot();
```

Quer√≠an capturar varias instant√°neas en diferentes puntos de la vida √∫til de la aplicaci√≥n, de modo que el visor de memoria de DevTools pudiera mostrar la diferencia entre los montones en diferentes momentos. El problema era que capturar una sola instant√°nea de tama√±o completo (500 MB) estaba tomando **m√°s de 30 minutos**!

Era esta lentitud en el flujo de trabajo de an√°lisis de memoria lo que necesit√°bamos resolver.

## Delimitando el problema

Entonces, los ingenieros de Bloomberg comenzaron a investigar el problema utilizando algunos par√°metros de V8. Como se describe en [esta publicaci√≥n](https://blogs.igalia.com/dape/2023/05/18/javascript-memory-profiling-with-heap-snapshot/), Node.js y V8 tienen algunos par√°metros de l√≠nea de comandos √∫tiles que pueden ayudar con esto. Estas opciones se utilizaron para crear las instant√°neas de mont√≥n, simplificar la reproducci√≥n y mejorar la observabilidad:

- `--max-old-space-size=100`: Esto limita el mont√≥n a 100 megabytes y ayuda a reproducir el problema mucho m√°s r√°pido.
- `--heapsnapshot-near-heap-limit=10`: Este es un par√°metro espec√≠fico de l√≠nea de comandos de Node.js que indica a Node.js que genere una instant√°nea cada vez que est√© cerca de quedarse sin memoria. Est√° configurado para generar hasta 10 instant√°neas en total. Esto evita el desgaste donde el programa con falta de memoria pasa mucho tiempo produciendo m√°s instant√°neas de las necesarias.
- `--enable-etw-stack-walking`: Esto permite a herramientas como ETW, WPA y xperf ver la pila JS que ha sido llamada en V8. (disponible en Node.js v20+)
- `--interpreted-frames-native-stack`: Esta bandera se usa en combinaci√≥n con herramientas como ETW, WPA y xperf para ver la pila nativa al realizar perfiles. (disponible en Node.js v20+).

Cuando el tama√±o del mont√≥n de V8 se acerca al l√≠mite, V8 fuerza una recolecci√≥n de basura para reducir el uso de memoria. Tambi√©n notifica al incrustador sobre esto. La bandera `--heapsnapshot-near-heap-limit` en Node.js genera una nueva instant√°nea de mont√≥n tras la notificaci√≥n. En el caso de prueba, el uso de memoria disminuye, pero, despu√©s de varias iteraciones, la recolecci√≥n de basura finalmente no puede liberar suficiente espacio y, por lo tanto, la aplicaci√≥n se termina con un error de *Falta de Memoria*.

Tomaron grabaciones utilizando Windows Performance Analyzer (ver m√°s abajo) para delimitar el problema. Esto revel√≥ que la mayor parte del tiempo de CPU se estaba gastando dentro del Explorador de Mont√≥n de V8. Espec√≠ficamente, tom√≥ alrededor de 30 minutos solo caminar por el mont√≥n para visitar cada nodo y recolectar el nombre. Esto no parec√≠a tener mucho sentido ‚Äî ¬øpor qu√© grabar el nombre de cada propiedad tomar√≠a tanto tiempo?

Fue entonces cuando se me pidi√≥ que echara un vistazo.

## Cuantificando el problema

El primer paso fue agregar soporte en V8 para comprender mejor d√≥nde se invierte el tiempo durante la captura de instant√°neas de mont√≥n. El proceso de captura en s√≠ se divide en dos fases: generaci√≥n y luego serializaci√≥n. Implementamos [este parche](https://chromium-review.googlesource.com/c/v8/v8/+/4428810) en el upstream para introducir una nueva bandera de l√≠nea de comandos `--profile_heap_snapshot` en V8, lo que habilita el registro de los tiempos de generaci√≥n y serializaci√≥n.

¬°Usando esta bandera, aprendimos algunas cosas interesantes!

Primero, pudimos observar la cantidad exacta de tiempo que V8 estaba dedicando a generar cada instant√°nea. En nuestro caso de prueba reducido, la primera tom√≥ 5 minutos, la segunda tom√≥ 8 minutos, y cada instant√°nea subsecuente segu√≠a tardando m√°s y m√°s tiempo. Casi todo este tiempo se gast√≥ en la fase de generaci√≥n.

Esto tambi√©n nos permiti√≥ cuantificar el tiempo dedicado a la generaci√≥n de instant√°neas con un gasto m√≠nimo, lo cual nos ayud√≥ a aislar e identificar desaceleraciones similares en otras aplicaciones ampliamente usadas de JavaScript, en particular, ESLint en TypeScript. As√≠ que sabemos que el problema no era espec√≠fico de una aplicaci√≥n.

Adem√°s, encontramos que el problema ocurr√≠a tanto en Windows como en Linux. El problema tampoco era espec√≠fico de una plataforma.

## Primera optimizaci√≥n: mejora del hashing en `StringsStorage`

Para identificar qu√© estaba causando el retraso excesivo, perfil√© el script que fallaba usando [Windows Performance Toolkit](https://learn.microsoft.com/en-us/windows-hardware/test/wpt/).

Cuando abr√≠ la grabaci√≥n con [Windows Performance Analyzer](https://learn.microsoft.com/en-us/windows-hardware/test/wpt/windows-performance-analyzer), esto fue lo que encontr√©:

![](/_img/speeding-up-v8-heap-snapshots/wpa-1.png)


Un tercio de las muestras se gast√≥ en `v8::internal::StringsStorage::GetEntry`:

```cpp
181 base::HashMap::Entry* StringsStorage::GetEntry(const char* str, int len) {
182   uint32_t hash = ComputeStringHash(str, len);
183   return names_.LookupOrInsert(const_cast<char*>(str), hash);
184 }
```

Debido a que esto se ejecut√≥ con una compilaci√≥n de versi√≥n final, la informaci√≥n de las llamadas a funciones integradas se comprimi√≥ en `StringsStorage::GetEntry()`. Para averiguar exactamente cu√°nto tiempo estaban tomando las llamadas a funciones integradas, agregu√© la columna ‚ÄúN√∫mero de l√≠nea de origen‚Äù al desglose y encontr√© que la mayor parte del tiempo se gastaba en la l√≠nea 182, que era una llamada a `ComputeStringHash()`:

![](/_img/speeding-up-v8-heap-snapshots/wpa-2.png)

As√≠ que m√°s del 30% del tiempo de generaci√≥n de instant√°neas se gast√≥ en `ComputeStringHash()`, pero ¬øpor qu√©?

Primero hablemos de `StringsStorage`. Su prop√≥sito es almacenar una copia √∫nica de todas las cadenas que se usar√°n en la instant√°nea del heap. Para un acceso r√°pido y para evitar duplicados, esta clase utiliza un hashmap respaldado por un arreglo, donde las colisiones se manejan almacenando elementos en la siguiente ubicaci√≥n libre en el arreglo.

Empec√© a sospechar que el problema podr√≠a deberse a colisiones, lo que podr√≠a llevar a b√∫squedas largas en el arreglo. As√≠ que agregu√© registros exhaustivos para ver las claves hash generadas y, al insertar, observar qu√© tan lejos estaba entre la posici√≥n esperada calculada a partir de la clave hash y la posici√≥n real donde termin√≥ la entrada debido a colisiones.

En los registros, las cosas estaban... mal: el desplazamiento de muchos elementos era superior a 20 y, en el peor de los casos, del orden de miles.

Parte del problema era causado por cadenas num√©ricas, especialmente cadenas para un rango amplio de n√∫meros consecutivos. El algoritmo de la clave hash ten√≠a dos implementaciones: una para cadenas num√©ricas y otra para otras cadenas. Mientras que la funci√≥n de hash para cadenas era bastante cl√°sica, la implementaci√≥n para cadenas num√©ricas b√°sicamente devolv√≠a el valor del n√∫mero precedido por la cantidad de d√≠gitos:

```cpp
int32_t OriginalHash(const std::string& numeric_string) {
  int kValueBits = 24;

  int32_t mask = (1 << kValueBits) - 1; /* 0xffffff */
  return (numeric_string.length() << kValueBits) | (numeric_string & mask);
}
```

| `x` | `OriginalHash(x)` |
| --: | ----------------: |
|   0 |       `0x1000000` |
|   1 |       `0x1000001` |
|   2 |       `0x1000002` |
|   3 |       `0x1000003` |
|  10 |       `0x200000a` |
|  11 |       `0x200000b` |
| 100 |       `0x3000064` |

Esta funci√≥n era problem√°tica. Algunos ejemplos de problemas con esta funci√≥n de hash:

- Una vez que insertamos una cadena cuya clave hash era un n√∫mero peque√±o, encontr√°bamos colisiones al intentar almacenar otro n√∫mero en esa ubicaci√≥n, y habr√≠a colisiones similares si trat√°bamos de almacenar n√∫meros subsecuentes consecutivamente.
- O a√∫n peor: si ya hab√≠a muchos n√∫meros consecutivos almacenados en el mapa y quer√≠amos insertar una cadena cuya clave hash estaba en ese rango, ten√≠amos que mover la entrada por todas las ubicaciones ocupadas hasta encontrar una ubicaci√≥n libre.

¬øQu√© hice para solucionarlo? Como el problema proviene principalmente de n√∫meros representados como cadenas que caen en posiciones consecutivas, modifiqu√© la funci√≥n hash para que rotara el valor hash resultante 2 bits hacia la izquierda.

```cpp
int32_t NewHash(const std::string& numeric_string) {
  return OriginalHash(numeric_string) << 2;
}
```

| `x` | `OriginalHash(x)` | `NewHash(x)` |
| --: | ----------------: | -----------: |
|   0 |       `0x1000000` |  `0x4000000` |
|   1 |       `0x1000001` |  `0x4000004` |
|   2 |       `0x1000002` |  `0x4000008` |
|   3 |       `0x1000003` |  `0x400000c` |
|  10 |       `0x200000a` |  `0x8000028` |
|  11 |       `0x200000b` |  `0x800002c` |
| 100 |       `0x3000064` |  `0xc000190` |

As√≠ que para cada par de n√∫meros consecutivos, introdujimos 3 posiciones libres entre ellos. Esta modificaci√≥n se eligi√≥ porque las pruebas emp√≠ricas con varios conjuntos de trabajo mostraron que funcionaba mejor para minimizar colisiones.

[Esta soluci√≥n de hashing](https://chromium-review.googlesource.com/c/v8/v8/+/4428811) se ha implementado en V8.

## Segunda optimizaci√≥n: almacenamiento en cach√© de posiciones de fuente

Despu√©s de solucionar el problema de hashing, volvimos a analizar y encontramos una oportunidad de optimizaci√≥n adicional que reducir√≠a una parte significativa del tiempo de procesamiento.

Al generar un snapshot del heap, para cada funci√≥n en el heap, V8 trata de registrar su posici√≥n de inicio en un par de n√∫meros de l√≠nea y columna. Esta informaci√≥n se utiliza por DevTools para mostrar un enlace al c√≥digo fuente de la funci√≥n. Sin embargo, durante la compilaci√≥n habitual, V8 solo guarda la posici√≥n de inicio de cada funci√≥n en forma de un desplazamiento lineal desde el principio del script. Para calcular los n√∫meros de l√≠nea y columna basados en el desplazamiento lineal, V8 necesita recorrer todo el script y registrar d√≥nde est√°n los saltos de l√≠nea. Este c√°lculo resulta muy costoso.

Normalmente, despu√©s de que V8 termina de calcular los desplazamientos de los saltos de l√≠nea en un script, los almacena en un nuevo array adjunto al script. Desafortunadamente, la implementaci√≥n del snapshot no puede modificar el heap mientras lo recorre, as√≠ que la informaci√≥n de l√≠nea reci√©n calculada no puede almacenarse en cach√©.

¬øLa soluci√≥n? Antes de generar el snapshot del heap, ahora iteramos sobre todos los scripts en el contexto de V8 para calcular y almacenar en cach√© los desplazamientos de los saltos de l√≠nea. Como esto no se realiza al recorrer el heap para generar el snapshot, todav√≠a es posible modificar el heap y guardar las posiciones de l√≠nea origen como un cach√©.

[La soluci√≥n para el almacenamiento en cach√© de los desplazamientos de los saltos de l√≠nea](https://chromium-review.googlesource.com/c/v8/v8/+/4538766) tambi√©n ha sido implementada en V8.

## ¬øLo hicimos r√°pido?

Despu√©s de habilitar ambas soluciones, volvimos a analizar. Nuestras dos soluciones solo afectan el tiempo de generaci√≥n del snapshot, por lo que, como se esperaba, los tiempos de serializaci√≥n del snapshot no se vieron afectados.

Al operar sobre un programa JS que contiene‚Ä¶

- JS de desarrollo, el tiempo de generaci√≥n es **50% m√°s r√°pido** üëç
- JS de producci√≥n, el tiempo de generaci√≥n es **90% m√°s r√°pido** üòÆ

¬øPor qu√© hubo una diferencia tan notable entre el c√≥digo de producci√≥n y el de desarrollo? El c√≥digo de producci√≥n se optimiza mediante empaquetado y minificaci√≥n, por lo que hay menos archivos JS, y estos archivos tienden a ser grandes. Lleva m√°s tiempo calcular las posiciones de las l√≠neas fuente para estos archivos grandes, por lo que se benefician m√°s cuando podemos almacenar en cach√© la posici√≥n de la fuente y evitar c√°lculos repetidos.

Las optimizaciones fueron validadas en entornos objetivo tanto en Windows como en Linux.

Para el problema particularmente desafiante enfrentado originalmente por los ingenieros de Bloomberg, el tiempo total de captura de un snapshot de 100 MB se redujo de unos dolorosos 10 minutos a unos muy agradables 6 segundos. Eso es **un incremento de rendimiento de 100√ó!** üî•

Las optimizaciones son mejoras gen√©ricas que esperamos que sean ampliamente aplicables para cualquier persona que realice depuraci√≥n de memoria en V8, Node.js y Chromium. Estas mejoras se implementaron en V8 v11.5.130, lo que significa que se encuentran en Chromium 115.0.5576.0. Esperamos que Node.js adopte estas optimizaciones en la pr√≥xima versi√≥n mayor de semver.

## ¬øQu√© sigue?

Primero, ser√≠a √∫til que Node.js aceptara la nueva bandera `--profile-heap-snapshot` en `NODE_OPTIONS`. En algunos casos de uso, los usuarios no pueden controlar directamente las opciones de l√≠nea de comandos que se pasan a Node.js y tienen que configurarlas a trav√©s de la variable de entorno `NODE_OPTIONS`. Actualmente, Node.js filtra las opciones de l√≠nea de comandos de V8 configuradas en la variable de entorno y solo permite un subconjunto conocido, lo que podr√≠a dificultar la prueba de nuevas banderas de V8 en Node.js, como sucedi√≥ en nuestro caso.

La precisi√≥n de la informaci√≥n en los snapshots podr√≠a mejorarse m√°s. Hoy en d√≠a, la informaci√≥n de cada l√≠nea del c√≥digo fuente del script se almacena en una representaci√≥n dentro del heap de V8. Esto es un problema porque queremos medir el heap con precisi√≥n sin que la sobrecarga de medici√≥n del rendimiento afecte al objeto que estamos observando. Idealmente, almacenar√≠amos la cach√© de la informaci√≥n de l√≠nea fuera del heap de V8 para que la informaci√≥n de los snapshots del heap sea m√°s precisa.

Finalmente, ahora que hemos mejorado la fase de generaci√≥n, el mayor costo ahora est√° en la fase de serializaci√≥n. Un an√°lisis adicional podr√≠a revelar nuevas oportunidades de optimizaci√≥n en la serializaci√≥n.

## Cr√©ditos

Esto fue posible gracias al trabajo de ingenieros de [Igalia](https://www.igalia.com/) y [Bloomberg](https://techatbloomberg.com/).
