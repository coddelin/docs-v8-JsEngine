---
title: 'Die Kosten von JavaScript im Jahr 2019'
author: 'Addy Osmani ([@addyosmani](https://twitter.com/addyosmani)), JavaScript-Hausmeister, und Mathias Bynens ([@mathias](https://twitter.com/mathias)), Hauptthread-Befreier'
avatars:
  - 'addy-osmani'
  - 'mathias-bynens'
date: 2019-06-25
tags:
  - internals
  - parsing
description: 'Die dominierenden Kosten bei der Verarbeitung von JavaScript sind der Download und die CPU-Ausf√ºhrungszeit.'
tweet: '1143531042361487360'
---
:::note
**Hinweis:** Wenn Sie es bevorzugen, eine Pr√§sentation anzusehen statt Artikel zu lesen, dann genie√üen Sie das unten stehende Video! Andernfalls √ºberspringen Sie das Video und lesen Sie weiter.
:::

<figure>
  <div class="video video-16:9">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/X9eRLElSW1c" allow="picture-in-picture" allowfullscreen loading="lazy"></iframe>
  </div>
  <figcaption><a href="https://www.youtube.com/watch?v=X9eRLElSW1c">‚ÄûDie Kosten von JavaScript‚Äú</a>, pr√§sentiert von Addy Osmani auf der #PerfMatters-Konferenz 2019.</figcaption>
</figure>

<!--truncate-->
Eine gro√üe Ver√§nderung bei [den Kosten von JavaScript](https://medium.com/@addyosmani/the-cost-of-javascript-in-2018-7d8950fbb5d4) in den letzten Jahren ist eine Verbesserung der Geschwindigkeit, mit der Browser Skripte analysieren und kompilieren k√∂nnen. **Im Jahr 2019 sind die dominierenden Kosten bei der Verarbeitung von Skripten nun der Download und die CPU-Ausf√ºhrungszeit.**

Die Benutzerinteraktion kann verz√∂gert werden, wenn der Hauptthread des Browsers mit der Ausf√ºhrung von JavaScript besch√§ftigt ist. Daher kann die Optimierung der Engp√§sse bei der Skriptausf√ºhrungszeit und im Netzwerk sehr wirkungsvoll sein.

## Umsetzbare Empfehlungen auf hoher Ebene

Was bedeutet das f√ºr Webentwickler? Die Kosten f√ºr das Parsen und Kompilieren sind **nicht mehr so langsam**, wie wir einst dachten. Die drei Schwerpunkte f√ºr JavaScript-Bundles sind:

- **Verbessern Sie die Downloadzeit**
    - Halten Sie Ihre JavaScript-Bundles klein, insbesondere f√ºr mobile Ger√§te. Kleine Bundles verbessern die Downloadgeschwindigkeit, verringern den Speicherverbrauch und reduzieren die CPU-Kosten.
    - Vermeiden Sie es, nur ein einzelnes gro√ües Bundle zu haben; wenn ein Bundle etwa 50‚Äì100 kB √ºberschreitet, teilen Sie es in mehrere kleinere Bundles auf. (Mit HTTP/2-Multiplexing k√∂nnen mehrere Anfrage- und Antwortnachrichten gleichzeitig verarbeitet werden, wodurch der Overhead zus√§tzlicher Anfragen reduziert wird.)
    - Auf mobilen Ger√§ten sollten Sie deutlich weniger ausliefern, nicht nur wegen der Netzwerkgeschwindigkeit, sondern auch um den reinen Speicherverbrauch gering zu halten.
- **Verbessern Sie die Ausf√ºhrungszeit**
    - Vermeiden Sie [Long Tasks](https://w3c.github.io/longtasks/), die den Hauptthread besch√§ftigt halten und die Zeit verz√∂gern k√∂nnen, bis Seiten interaktiv sind. Nach dem Download ist die Skriptausf√ºhrungszeit nun ein dominanter Kostenfaktor.
- **Vermeiden Sie gro√üe Inline-Skripte** (da sie immer noch im Hauptthread analysiert und kompiliert werden). Eine gute Faustregel ist: Wenn das Skript mehr als 1 kB gro√ü ist, vermeiden Sie das Inlining (auch weil ab 1 kB [Code-Caching](/blog/code-caching-for-devs) f√ºr externe Skripte greift).

## Warum sind Download- und Ausf√ºhrungszeit wichtig?

Warum ist es wichtig, Download- und Ausf√ºhrungszeiten zu optimieren? Downloadzeiten sind entscheidend f√ºr Netzwerke mit niedriger Bandbreite. Trotz des Wachstums von 4G (und sogar 5G) weltweit, bleiben unsere [effektiven Verbindungstypen](https://developer.mozilla.org/en-US/docs/Web/API/NetworkInformation/effectiveType) uneinheitlich, wobei viele von uns Geschwindigkeiten erleben, die wie 3G (oder schlechter) wirken, wenn wir unterwegs sind.

Die JavaScript-Ausf√ºhrungszeit ist wichtig f√ºr Telefone mit langsamen CPUs. Aufgrund von Unterschieden in CPU, GPU und thermischem Drosseln gibt es gro√üe Unterschiede in der Leistung zwischen High-End- und Low-End-Telefonen. Dies ist wichtig f√ºr die Leistung von JavaScript, da die Ausf√ºhrung CPU-gebunden ist.

Tats√§chlich kann von der gesamten Zeit, die eine Seite in einem Browser wie Chrome zum Laden ben√∂tigt, bis zu 30 % dieser Zeit f√ºr die JavaScript-Ausf√ºhrung aufgewendet werden. Unten sehen Sie einen Seitenladevorgang von einer Website mit einem ziemlich typischen Arbeitsaufwand (Reddit.com) auf einem High-End-Desktop:

![Die Verarbeitung von JavaScript macht 10‚Äì30 % der Zeit aus, die in V8 w√§hrend des Seitenladens verbraucht wird.](/_img/cost-of-javascript-2019/reddit-js-processing.svg)

Auf mobilen Ger√§ten dauert es 3‚Äì4√ó l√§nger, bis ein durchschnittliches Telefon (Moto G4) das JavaScript von Reddit ausf√ºhrt, verglichen mit einem High-End-Ger√§t (Pixel 3), und mehr als 6√ó so lange auf einem Low-End-Ger√§t (das &lt;$100 Alcatel 1X):

![Die Kosten des JavaScripts von Reddit in verschiedenen Ger√§tekategorien (Low-End, Durchschnitt und High-End)](/_img/cost-of-javascript-2019/reddit-js-processing-devices.svg)

:::note
**Hinweis:** Reddit bietet unterschiedliche Erlebnisse f√ºr Desktop- und mobile Web an, daher k√∂nnen die MacBook-Pro-Ergebnisse nicht mit den anderen Ergebnissen verglichen werden.
:::

Wenn Sie versuchen, die JavaScript-Ausf√ºhrungszeit zu optimieren, achten Sie auf [Langsame Aufgaben](https://web.dev/long-tasks-devtools/), die den UI-Thread m√∂glicherweise √ºber lange Zeitr√§ume monopolisieren. Diese k√∂nnen kritische Aufgaben daran hindern, ausgef√ºhrt zu werden, selbst wenn die Seite optisch bereit aussieht. Teilen Sie diese Aufgaben in kleinere Aufgaben auf. Durch das Aufteilen Ihres Codes und die Priorisierung der Reihenfolge, in der er geladen wird, k√∂nnen Sie Seiten schneller interaktiv machen und hoffentlich die Eingabelatenz verringern.

![Langsame Aufgaben monopolisieren den Haupt-Thread. Sie sollten sie aufteilen.](/_img/cost-of-javascript-2019/long-tasks.png)

## Was hat V8 getan, um das Parsen/Kompilieren zu verbessern?

Die Geschwindigkeit des Roh-JavaScript-Parsings in V8 hat sich seit Chrome 60 verdoppelt. Gleichzeitig sind die Kosten f√ºr das reine Parsen (und Kompilieren) durch andere Optimierungsarbeiten in Chrome, die dies parallelisieren, weniger sichtbar/wichtig geworden.

V8 hat die Menge der Parse- und Kompilierungsarbeiten auf dem Haupt-Thread durchschnittlich um 40 % reduziert (z. B. 46 % bei Facebook, 62 % bei Pinterest), mit der h√∂chsten Verbesserung von 81 % (YouTube), indem das Parsen und Kompilieren auf einem Worker-Thread durchgef√ºhrt wird. Dies erfolgt zus√§tzlich zum vorhandenen Off-Main-Thread-Streaming-Parse/Kompilieren.

![V8-Parsetzeiten in verschiedenen Versionen](/_img/cost-of-javascript-2019/chrome-js-parse-times.svg)

Wir k√∂nnen auch die Auswirkungen der √Ñnderungen auf die CPU-Zeit in verschiedenen Versionen von V8 in Chrome-Versionen visualisieren. In der gleichen Zeit, die Chrome 61 f√ºr das Parsen der JS von Facebook ben√∂tigte, kann Chrome 75 jetzt sowohl die JS von Facebook als auch die JS von Twitter sechsmal parsen.

![In der Zeit, die Chrome 61 ben√∂tigte, um Facebooks JS zu parsen, kann Chrome 75 jetzt sowohl Facebooks JS als auch sechsmal Twitters JS parsen.](/_img/cost-of-javascript-2019/js-parse-times-websites.svg)

Lassen Sie uns genauer betrachten, wie diese √Ñnderungen erm√∂glicht wurden. Kurz gesagt, Skript-Ressourcen k√∂nnen streaming-geparst und -kompiliert auf einem Worker-Thread werden, was bedeutet:

- V8 kann JavaScript parsen+kompilieren, ohne den Haupt-Thread zu blockieren.
- Das Streaming beginnt, sobald der vollst√§ndige HTML-Parser ein `<script>`-Tag entdeckt. F√ºr Parser-blockierende Skripte pausiert der HTML-Parser, w√§hrend er bei asynchronen Skripten weiterl√§uft.
- F√ºr die meisten realen Verbindungsgeschwindigkeiten parst V8 schneller als der Download, sodass V8 ein paar Millisekunden nach dem Herunterladen der letzten Skript-Bytes mit dem Parsing+Kompilieren fertig ist.

Die nicht so kurze Erkl√§rung ist ... √Ñltere Versionen von Chrome w√ºrden ein Skript vollst√§ndig herunterladen, bevor mit dem Parsen begonnen wird. Dies ist ein einfacher Ansatz, nutzt die CPU jedoch nicht vollst√§ndig aus. Zwischen den Versionen 41 und 68 begann Chrome damit, asynchrone und verz√∂gerte Skripte auf einem separaten Thread zu parsen, sobald der Download beginnt.

![Skripte kommen in mehreren Teilen an. V8 beginnt mit dem Streaming, sobald es mindestens 30 kB gesehen hat.](/_img/cost-of-javascript-2019/script-streaming-1.svg)

In Chrome 71 wechselten wir zu einer task-basierten Einrichtung, bei der der Scheduler mehrere asynchrone/verz√∂gerte Skripte gleichzeitig parsen konnte. Die Auswirkungen dieser √Ñnderung waren eine ~20%ige Reduzierung der Parse-Zeit auf dem Haupt-Thread, was zu einer Gesamtheit von ~2% Verbesserung in TTI/FID f√ºhrte, gemessen auf realen Websites.

![Chrome 71 wechselte zu einer task-basierten Einrichtung, bei der der Scheduler mehrere asynchrone/verz√∂gerte Skripte gleichzeitig parsen konnte.](/_img/cost-of-javascript-2019/script-streaming-2.svg)

In Chrome 72 wechselten wir dazu, Streaming als Hauptweg f√ºr das Parsen zu nutzen: Auch regul√§re synchronisierte Skripte werden nun auf diese Weise geparst (keine Inline-Skripte jedoch). Au√üerdem haben wir aufgeh√∂rt, das task-basierte Parse abzubrechen, falls der Haupt-Thread es ben√∂tigt, da dies nur unn√∂tig bereits erledigte Arbeiten dupliziert.

[Fr√ºhere Versionen von Chrome](/blog/v8-release-75#script-streaming-directly-from-network) unterst√ºtzten Streaming-Parsen und -Kompilieren, bei denen die Skript-Quelldaten, die aus dem Netzwerk kamen, zuerst auf dem Haupt-Thread von Chrome verarbeitet werden mussten, bevor sie an den Streamer weitergeleitet wurden.

Dies f√ºhrte oft dazu, dass der Streaming-Parser auf Daten wartete, die bereits aus dem Netzwerk ankamen, die jedoch aufgrund anderer Arbeiten auf dem Haupt-Thread (wie HTML-Parsing, Layout oder JavaScript-Ausf√ºhrung) noch nicht an den Streaming-Task weitergeleitet wurden.

Wir experimentieren nun damit, das Parsing beim Preload zu starten, wobei das Bounce-Verhalten des Haupt-Threads zuvor ein Blocker daf√ºr war.

Leszek Swirskis BlinkOn-Pr√§sentation geht auf weitere Details ein:

<figure>
  <div class="video video-16:9">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/D1UJgiG4_NI" allow="picture-in-picture" allowfullscreen loading="lazy"></iframe>
  </div>
  <figcaption><a href="https://www.youtube.com/watch?v=D1UJgiG4_NI">‚ÄûJavaScript in Null* Zeit parsen‚Äú</a>, pr√§sentiert von Leszek Swirski auf BlinkOn 10.</figcaption>
</figure>

## Wie spiegeln sich diese √Ñnderungen in DevTools wider?

Zus√§tzlich zu den oben genannten gab es [ein Problem in DevTools](https://bugs.chromium.org/p/chromium/issues/detail?id=939275), das die gesamte Parser-Aufgabe so darstellte, dass es darauf hindeutet, dass sie die CPU nutzt (vollst√§ndiger Block). Der Parser blockiert jedoch immer, wenn er keine Daten erh√§lt (die √ºber den Haupt-Thread weitergeleitet werden m√ºssen). Seit wir von einem einzigen Streamer-Thread zu Streaming-Tasks gewechselt sind, wurde dies wirklich offensichtlich. Hier ist, was Sie in Chrome 69 sehen w√ºrden:

![Das DevTools-Problem, das die gesamte Parser-Aufgabe so darstellte, dass es darauf hindeutet, dass sie die CPU nutzt (vollst√§ndiger Block)](/_img/cost-of-javascript-2019/devtools-69.png)

Die Aufgabe ‚ÄûSkript analysieren‚Äú wird als 1,08 Sekunden angezeigt. Aber das Parsen von JavaScript ist eigentlich nicht so langsam! Die meiste Zeit wird damit verbracht, nichts zu tun, au√üer darauf zu warten, dass Daten √ºber den Hauptthread √ºbertragen werden.

Chrome 76 zeigt ein anderes Bild:

![In Chrome 76 wird das Parsen in mehrere kleinere Streaming-Aufgaben unterteilt.](/_img/cost-of-javascript-2019/devtools-76.png)

Generell ist die Leistungs√ºbersicht in den DevTools gro√üartig, um einen √úberblick dar√ºber zu bekommen, was auf Ihrer Seite passiert. F√ºr detaillierte V8-spezifische Metriken wie JavaScript-Parse- und Kompilierungszeiten empfehlen wir [die Verwendung von Chrome Tracing mit Runtime Call Stats (RCS)](/docs/rcs). In den RCS-Ergebnissen zeigen `Parse-Background` und `Compile-Background`, wie viel Zeit f√ºr das Parsen und Kompilieren von JavaScript au√üerhalb des Hauptthreads aufgewendet wird, w√§hrend `Parse` und `Compile` die Hauptthread-Metriken erfassen.

![](/_img/cost-of-javascript-2019/rcs.png)

## Was ist die Auswirkung dieser √Ñnderungen in der Realit√§t?

Sehen wir uns einige Beispiele von realen Webseiten an und wie Skript-Streaming angewendet wird.

![Zeitaufwand auf Haupt- vs. Worker-Thread beim Parsen und Kompilieren von Reddits JS auf einem MacBook Pro](/_img/cost-of-javascript-2019/reddit-main-thread.svg)

Reddit.com hat mehrere 100 kB+ Bundles, die in √§u√üeren Funktionen gewickelt sind und eine Menge [lazy compilation](/blog/preparser) im Hauptthread verursachen. In der obigen Grafik z√§hlt die Zeit des Hauptthreads wirklich, da das Besch√§ftigen des Hauptthreads die Interaktivit√§t verz√∂gern kann. Reddit verbringt die meiste Zeit im Hauptthread mit minimaler Nutzung des Worker-/Hintergrundthreads.

Sie w√ºrden davon profitieren, einige ihrer gr√∂√üeren Bundles in kleinere (z. B. 50 kB) ohne Umh√ºllung aufzuteilen, um die Parallelisierung zu maximieren ‚Äî so dass jedes Bundle separat gestreamt-geparst und kompiliert werden k√∂nnte und das Parsen/Kompilieren des Hauptthreads w√§hrend des Startens reduziert wird.

![Zeitaufwand auf Haupt- vs. Worker-Thread beim Parsen und Kompilieren von Facebooks JS auf einem MacBook Pro](/_img/cost-of-javascript-2019/facebook-main-thread.svg)

Wir k√∂nnen uns auch eine Seite wie Facebook.com ansehen. Facebook l√§dt ~6 MB komprimiertes JS √ºber ~292 Anfragen, teils asynchron, teils vorab geladen und teils mit niedriger Priorit√§t abgerufen. Viele ihrer Skripte sind sehr klein und granular ‚Äî dies kann bei der Gesamtparallelisierung im Hintergrund-/Worker-Thread helfen, da diese kleineren Skripte gleichzeitig gestreamt-geparst/kompiliert werden k√∂nnen.

Beachten Sie, dass Sie wahrscheinlich nicht Facebook sind und wahrscheinlich keine langlebige App wie Facebook oder Gmail haben, bei der so viele Skripte auf dem Desktop gerechtfertigt sein k√∂nnten. Im Allgemeinen sollten Sie jedoch Ihre Bundles grob halten und nur das laden, was Sie ben√∂tigen.

Obwohl die meisten Arbeiten zum Parsen und Kompilieren von JavaScript auf einem Hintergrundthread im Streaming-Modus stattfinden k√∂nnen, muss noch ein Teil der Arbeit im Hauptthread erfolgen. Wenn der Hauptthread besch√§ftigt ist, kann die Seite nicht auf Benutzereingaben reagieren. Behalten Sie die Auswirkungen sowohl des Herunterladens als auch des Ausf√ºhrens von Code auf Ihre Benutzererfahrung im Auge.

:::hinweis
**Hinweis:** Derzeit implementieren nicht alle JavaScript-Engines und Browser Skript-Streaming als Ladeoptimierung. Wir glauben dennoch, dass die hier aufgef√ºhrte Anleitung zu guten Benutzererfahrungen √ºbergreifend f√ºhrt.
:::

## Die Kosten f√ºr das Parsen von JSON

Da die JSON-Grammatik viel einfacher als die JavaScript-Grammatik ist, kann JSON effizienter geparst werden als JavaScript. Dieses Wissen kann genutzt werden, um die Startleistung von Web-Apps zu verbessern, die gro√üe JSON-√§hnliche Konfigurationsobjektliterale (wie Inline-Redux-Stores) versenden. Anstatt die Daten wie folgt als JavaScript-Objektliteral in den Code einzubetten:

```js
const data = { foo: 42, bar: 1337 }; // üêå
```

‚Ä¶kann es im JSON-stringifizierten Format dargestellt und dann zur Laufzeit geparst werden:

```js
const data = JSON.parse('{"foo":42,"bar":1337}'); // üöÄ
```

Solange der JSON-String nur einmal ausgewertet wird, ist die `JSON.parse`-Methode [viel schneller](https://github.com/GoogleChromeLabs/json-parse-benchmark) im Vergleich zum JavaScript-Objektliteral, insbesondere bei kalten Ladevorg√§ngen. Eine gute Faustregel ist, diese Technik f√ºr Objekte von 10 kB oder gr√∂√üer anzuwenden ‚Äî aber wie immer bei Leistungsratschl√§gen: Messen Sie die tats√§chlichen Auswirkungen, bevor Sie √Ñnderungen vornehmen.

![`JSON.parse('‚Ä¶')` ist [viel schneller](https://github.com/GoogleChromeLabs/json-parse-benchmark) zu parsen, zu kompilieren und auszuf√ºhren im Vergleich zu einem entsprechenden JavaScript-Literal ‚Äî nicht nur in V8 (1,7√ó so schnell), sondern in allen wichtigen JavaScript-Engines.](/_img/cost-of-javascript-2019/json.svg)

Das folgende Video erkl√§rt detaillierter, woher der Leistungsunterschied kommt, ab der Marke von 02:10.

<figure>
  <div class="video video-16:9">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/ff4fgQxPaO0?start=130" allow="picture-in-picture" allowfullscreen loading="lazy"></iframe>
  </div>
  <figcaption><a href="https://www.youtube.com/watch?v=ff4fgQxPaO0">‚ÄûSchnellere Apps mit <code>JSON.parse</code>‚Äú</a>, pr√§sentiert von Mathias Bynens auf der #ChromeDevSummit 2019.</figcaption>
</figure>

Sehen Sie sich [unseren _JSON ‚äÇ ECMAScript_ Feature-Erkl√§rer](/features/subsume-json#embedding-json-parse) f√ºr eine Beispielimplementierung an, die aus einem beliebigen Objekt ein g√ºltiges JavaScript-Programm erzeugt, das dieses mit `JSON.parse` analysiert.

Es gibt ein zus√§tzliches Risiko beim Verwenden von einfachen Objektliteralen f√ºr gro√üe Datenmengen: Sie k√∂nnten _zweimal_ analysiert werden!

1. Der erste Durchgang erfolgt, wenn das Literal vorgeparst wird.
2. Der zweite Durchgang erfolgt, wenn das Literal lazy-geparst wird.

Der erste Durchgang kann nicht vermieden werden. Gl√ºcklicherweise kann der zweite Durchgang vermieden werden, indem das Objektliteral auf Top-Level platziert wird oder innerhalb eines [PIFE](/blog/preparser#pife).

## Wie sieht es mit der Analyse/Compilierung bei wiederholten Besuchen aus?

Die (Byte-)Code-Caching-Optimierung von V8 kann helfen. Wenn ein Skript zum ersten Mal angefordert wird, l√§dt Chrome es herunter und gibt es an V8 zur Compilierung weiter. Es speichert die Datei auch im On-Disk-Cache des Browsers. Wenn die JS-Datei ein zweites Mal angefordert wird, nimmt Chrome die Datei aus dem Browser-Cache und gibt sie erneut an V8 zur Compilierung. Dieses Mal wird der kompilierte Code jedoch serialisiert und als Metadata an die zwischengespeicherte Skriptdatei angeh√§ngt.

![Visualisierung, wie Code-Caching in V8 funktioniert](/_img/cost-of-javascript-2019/code-caching.png)

Beim dritten Mal nimmt Chrome sowohl die Datei als auch die Metadata der Datei aus dem Cache und gibt beides an V8 weiter. V8 deserialisiert die Metadata und kann die Compilierung √ºberspringen. Code-Caching setzt ein, wenn die ersten beiden Besuche innerhalb von 72 Stunden stattfinden. Chrome hat auch ein aggressives Code-Caching, wenn ein Service-Arbeiter verwendet wird, um Skripts zu cachen. Sie k√∂nnen mehr √ºber Code-Caching in [Code-Caching f√ºr Webentwickler](/blog/code-caching-for-devs) lesen.

## Schlussfolgerungen

Download- und Ausf√ºhrungszeit sind die Hauptengp√§sse beim Laden von Skripten im Jahr 2019. Streben Sie ein kleines Paket an synchronen (eingebetteten) Skripten f√ºr Ihre Above-the-Fold-Inhalte an, mit einem oder mehreren verz√∂gerten Skripten f√ºr den Rest der Seite. Zerteilen Sie Ihre gro√üen Pakete, sodass Sie sich nur auf das Versenden von Code konzentrieren, den der Nutzer ben√∂tigt, wenn er ihn ben√∂tigt. Dies maximiert die Parallelisierung in V8.

Auf Mobilger√§ten sollten Sie weit weniger Skript versenden, aufgrund von Netzwerk, Speicherverbrauch und Ausf√ºhrungszeit bei langsameren CPUs. Balance zwischen Latenz und Cache-F√§higkeit hilft, die Menge an Parser- und Compilierungsarbeit zu maximieren, die au√üerhalb des Hauptthreads stattfinden kann.

## Weiterf√ºhrende Literatur

- [Blitzschnelles Parsen, Teil 1: Optimierung des Scanners](/blog/scanner)
- [Blitzschnelles Parsen, Teil 2: Lazy Parsing](/blog/preparser)
