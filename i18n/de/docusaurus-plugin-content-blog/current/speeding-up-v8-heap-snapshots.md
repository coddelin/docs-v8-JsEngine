---
title: "Beschleunigung von V8-Heap-Snapshots"
description: "Dieser Beitrag √ºber V8-Heap-Snapshots pr√§sentiert einige von Bloomberg-Ingenieuren entdeckte Leistungsprobleme und wie wir diese gel√∂st haben, um die JavaScript-Speicheranalyse schneller als je zuvor zu machen."
author: "Jose Dapena Paz"
date: 2023-07-27
tags:
 - Speicher
 - Werkzeuge
---
*Dieser Blog-Beitrag wurde von Jos√© Dapena Paz (Igalia) verfasst, mit Beitr√§gen von Jason Williams (Bloomberg), Ashley Claymore (Bloomberg), Rob Palmer (Bloomberg), Joyee Cheung (Igalia) und Shu-yu Guo (Google).*

In diesem Beitrag √ºber V8-Heap-Snapshots werde ich √ºber einige von Bloomberg-Ingenieuren entdeckte Leistungsprobleme sprechen und wie wir diese gel√∂st haben, um die JavaScript-Speicheranalyse schneller als je zuvor zu machen.

## Das Problem

Bloomberg-Ingenieure arbeiteten daran, ein Speicherleck in einer JavaScript-Anwendung zu diagnostizieren. Es trat mit *Out-Of-Memory*-Fehlern auf. F√ºr die getestete Anwendung war das V8-Heap-Limit auf etwa 1400 MB konfiguriert. Normalerweise sollte der Garbage Collector von V8 in der Lage sein, die Heap-Nutzung unter diesem Limit zu halten, daher deuteten die Fehler darauf hin, dass es wahrscheinlich ein Leck gab.

<!--truncate-->
Eine g√§ngige Technik zur Debugging eines routinem√§√üigen Szenarios mit Speicherlecks wie diesem ist es, zuerst einen Heap-Snapshot zu erfassen, diesen dann im "Memory"-Reiter der DevTools zu laden und herauszufinden, was am meisten Speicher verbraucht, indem man die verschiedenen Zusammenfassungen und Objektattribute untersucht. Im UI der DevTools kann der Heap-Snapshot im "Memory"-Reiter aufgenommen werden. F√ºr Node.js-Anwendungen kann der Heap-Snapshot [programmgesteuert ausgel√∂st werden](https://nodejs.org/en/docs/guides/diagnostics/memory/using-heap-snapshot) mit dieser API:

```js
require('v8').writeHeapSnapshot();
```

Sie wollten mehrere Snapshots zu verschiedenen Zeitpunkten im Lebenszyklus der Anwendung erfassen, sodass der Memory-Viewer der DevTools verwendet werden konnte, um die Unterschiede zwischen den Heaps zu verschiedenen Zeiten anzuzeigen. Das Problem war jedoch, dass das Erfassen eines einzelnen vollst√§ndigen Snapshots (500 MB) **√ºber 30 Minuten** dauerte!

Es war diese Langsamkeit im Workflow zur Speicheranalyse, die wir beheben mussten.

## Eingrenzung des Problems

Dann begannen Bloomberg-Ingenieure, das Problem mithilfe einiger V8-Parameter zu untersuchen. Wie in [diesem Beitrag](https://blogs.igalia.com/dape/2023/05/18/javascript-memory-profiling-with-heap-snapshot/) beschrieben, haben Node.js und V8 einige praktische Befehlszeilen-Parameter, die dabei helfen k√∂nnen. Diese Optionen wurden genutzt, um die Heap-Snapshots zu erstellen, die Reproduktion zu vereinfachen und die Beobachtbarkeit zu verbessern:

- `--max-old-space-size=100`: Dies begrenzt den Heap auf 100 Megabyte und hilft, das Problem viel schneller zu reproduzieren.
- `--heapsnapshot-near-heap-limit=10`: Dies ist ein spezifischer Node.js-Befehlszeilen-Parameter, der Node.js anweist, einen Snapshot zu erstellen, wenn der Speicher kurz davor steht, ersch√∂pft zu werden. Es ist konfiguriert, bis zu 10 Snapshots insgesamt zu erstellen. Dies verhindert ein ‚ÄûThrashing‚Äú, bei dem das speicherarme Programm viel Zeit damit verbringt, mehr Snapshots als n√∂tig zu erzeugen.
- `--enable-etw-stack-walking`: Erm√∂glicht Tools wie ETW, WPA und xperf, den JS-Stack zu sehen, der in V8 aufgerufen wurde. (verf√ºgbar in Node.js v20+)
- `--interpreted-frames-native-stack`: Dieses Flag wird in Kombination mit Tools wie ETW, WPA und xperf verwendet, um den nativen Stack beim Profilieren zu sehen. (verf√ºgbar in Node.js v20+).

Wenn die Gr√∂√üe des V8-Heaps das Limit erreicht, erzwingt V8 eine Garbage Collection, um die Speichernutzung zu reduzieren. Es benachrichtigt auch den Embedder dar√ºber. Das `--heapsnapshot-near-heap-limit`-Flag in Node.js erstellt bei Benachrichtigung einen neuen Heap-Snapshot. Im Testfall sinkt die Speichernutzung, aber nach mehreren Iterationen kann die Garbage Collection letztlich nicht gen√ºgend Speicherplatz freimachen, sodass die Anwendung mit einem *Out-Of-Memory*-Fehler beendet wird.

Sie machten Aufzeichnungen mit dem Windows Performance Analyzer (siehe unten), um das Problem einzugrenzen. Dies zeigte, dass die meiste CPU-Zeit im V8 Heap Explorer aufgewendet wurde. Insbesondere dauerte es etwa 30 Minuten, nur um den Heap zu durchlaufen, jeden Knoten zu besuchen und den Namen zu sammeln. Das schien nicht viel Sinn zu machen ‚Äì warum sollte das Aufzeichnen des Namens jeder Eigenschaft so lange dauern?

Zu diesem Zeitpunkt wurde ich gebeten, mir das Problem anzusehen.

## Quantifizieren des Problems

Der erste Schritt war die Unterst√ºtzung in V8 hinzuzuf√ºgen, um besser zu verstehen, wo die Zeit w√§hrend der Erfassung von Heap-Snapshots aufgewendet wird. Der Erfassungsprozess selbst ist in zwei Phasen unterteilt: Generierung und Serialisierung. Wir haben [diesen Patch](https://chromium-review.googlesource.com/c/v8/v8/+/4428810) upstream aufgenommen, um ein neues Befehlszeilenflag `--profile_heap_snapshot` in V8 einzuf√ºhren, das die Protokollierung der Zeiten f√ºr die Generierung und Serialisierung aktiviert.

Mit diesem Flag haben wir einige interessante Dinge gelernt!

Zun√§chst konnten wir die genaue Zeit beobachten, die V8 mit der Erstellung jedes Snapshots verbrachte. In unserem reduzierten Testfall dauerte der erste Snapshot 5 Minuten, der zweite 8 Minuten und jeder nachfolgende Snapshot ben√∂tigte immer mehr Zeit. Fast die gesamte Zeit wurde f√ºr die Erstellungsphase aufgewendet.

Dies erm√∂glichte uns auch, die mit der Snapshot-Erstellung verbrachte Zeit mit einem trivialen Overhead zu quantifizieren, was uns half, √§hnliche Verlangsamungen in anderen weit verbreiteten JavaScript-Anwendungen zu isolieren und zu identifizieren ‚Äì insbesondere ESLint auf TypeScript. So wussten wir, dass das Problem nicht spezifisch f√ºr eine Anwendung war.

Dar√ºber hinaus stellten wir fest, dass das Problem sowohl unter Windows als auch unter Linux auftrat. Das Problem war also auch nicht plattformspezifisch.

## Erste Optimierung: Verbesserte `StringsStorage`-Hashing

Um herauszufinden, was die √ºberm√§√üige Verz√∂gerung verursachte, profilierte ich das fehlerhafte Skript mit dem [Windows Performance Toolkit](https://learn.microsoft.com/en-us/windows-hardware/test/wpt/).

Als ich die Aufzeichnung mit dem [Windows Performance Analyzer](https://learn.microsoft.com/en-us/windows-hardware/test/wpt/windows-performance-analyzer) √∂ffnete, fand ich Folgendes:

![](/_img/speeding-up-v8-heap-snapshots/wpa-1.png)


Ein Drittel der Samples wurde in `v8::internal::StringsStorage::GetEntry` verbracht:

```cpp
181 base::HashMap::Entry* StringsStorage::GetEntry(const char* str, int len) {
182   uint32_t hash = ComputeStringHash(str, len);
183   return names_.LookupOrInsert(const_cast<char*>(str), hash);
184 }
```

Da dies mit einem Release-Build ausgef√ºhrt wurde, wurden die Informationen zu den eingebetteten Funktionsaufrufen in `StringsStorage::GetEntry()` zusammengefasst. Um genau herauszufinden, wie viel Zeit die eingebetteten Funktionsaufrufe beanspruchten, f√ºgte ich der Aufschl√ºsselung die Spalte ‚ÄûSource Line Number‚Äú hinzu und stellte fest, dass die meiste Zeit auf Zeile 182 verbracht wurde, die einen Aufruf von `ComputeStringHash()` enthielt:

![](/_img/speeding-up-v8-heap-snapshots/wpa-2.png)

√úber 30 % der Zeit f√ºr die Snapshot-Erstellung wurden in `ComputeStringHash()` verbracht, aber warum?

Sprechen wir zun√§chst √ºber `StringsStorage`. Es dient dazu, eine einzigartige Kopie aller Strings zu speichern, die im Heap-Snapshot verwendet werden. F√ºr schnellen Zugriff und zur Vermeidung von Duplikaten verwendet diese Klasse eine Hashmap, die durch ein Array gest√ºtzt wird, wobei Kollisionen durch Speichern von Elementen an der n√§chsten freien Position im Array behandelt werden.

Ich begann zu vermuten, dass das Problem durch Kollisionen verursacht werden k√∂nnte, die zu langen Suchvorg√§ngen im Array f√ºhren k√∂nnten. Daher f√ºgte ich umfassende Logs hinzu, um die generierten Hash-Schl√ºssel zu sehen und bei der Einf√ºgung zu sehen, wie weit die tats√§chliche Position des Eintrags von der berechneten Position des Hash-Schl√ºssels aufgrund von Kollisionen entfernt war.

In den Logs war etwas nicht in Ordnung: Der Offset vieler Elemente lag √ºber 20 und im schlimmsten Fall sogar im Bereich von Tausenden!

Ein Teil des Problems wurde durch numerische Strings verursacht ‚Äì insbesondere Strings f√ºr eine breite Reihe aufeinanderfolgender Zahlen. Der Hash-Schl√ºssel-Algorithmus hatte zwei Implementierungen, eine f√ºr numerische Strings und eine andere f√ºr andere Strings. W√§hrend die String-Hash-Funktion recht klassisch war, w√ºrde die Implementierung f√ºr numerische Strings im Wesentlichen den Wert der Zahl zur√ºckgeben, der durch die Anzahl der Ziffern vorangestellt wurde:

```cpp
int32_t OriginalHash(const std::string& numeric_string) {
  int kValueBits = 24;

  int32_t mask = (1 << kValueBits) - 1; /* 0xffffff */
  return (numeric_string.length() << kValueBits) | (numeric_string & mask);
}
```

| `x` | `OriginalHash(x)` |
| --: | ----------------: |
|   0 |       `0x1000000` |
|   1 |       `0x1000001` |
|   2 |       `0x1000002` |
|   3 |       `0x1000003` |
|  10 |       `0x200000a` |
|  11 |       `0x200000b` |
| 100 |       `0x3000064` |

Diese Funktion war problematisch. Ein paar Beispiele f√ºr Probleme mit dieser Hash-Funktion:

- Sobald wir einen String einf√ºgten, dessen Hash-Schl√ºsselwert eine kleine Zahl war, stie√üen wir auf Kollisionen, wenn wir versuchten, eine andere Zahl an dieser Position zu speichern. √Ñhnliche Kollisionen traten auch auf, wenn wir versuchten, aufeinanderfolgende Zahlen nacheinander zu speichern.
- Noch schlimmer: Wenn bereits viele aufeinanderfolgende Zahlen in der Map gespeichert waren und wir versuchten, einen String zu speichern, dessen Hash-Schl√ºsselwert in diesem Bereich lag, mussten wir den Eintrag entlang aller belegten Positionen bewegen, um eine freie Position zu finden.

Was habe ich getan, um dies zu beheben? Da das Problem haupts√§chlich durch Zahlen verursacht wird, die als Strings dargestellt werden und in aufeinanderfolgende Positionen fallen, habe ich die Hash-Funktion so modifiziert, dass der resultierende Hash-Wert um 2 Bits nach links rotiert wird.

```cpp
int32_t NewHash(const std::string& numeric_string) {
  return OriginalHash(numeric_string) << 2;
}
```

| `x` | `OriginalHash(x)` | `NewHash(x)` |
| --: | ----------------: | -----------: |
|   0 |       `0x1000000` |  `0x4000000` |
|   1 |       `0x1000001` |  `0x4000004` |
|   2 |       `0x1000002` |  `0x4000008` |
|   3 |       `0x1000003` |  `0x400000c` |
|  10 |       `0x200000a` |  `0x8000028` |
|  11 |       `0x200000b` |  `0x800002c` |
| 100 |       `0x3000064` |  `0xc000190` |

F√ºr jedes Paar aufeinanderfolgender Zahlen w√ºrden wir 3 freie Positionen dazwischen einf√ºhren. Diese Modifikation wurde ausgew√§hlt, weil empirische Tests mit mehreren Arbeitss√§tzen zeigten, dass sie am besten geeignet war, um Kollisionen zu minimieren.

[Dieser Hashing-Fix](https://chromium-review.googlesource.com/c/v8/v8/+/4428811) wurde in V8 integriert.

## Zweite Optimierung: Caching von Quellpositionen

Nach der Behebung des Hashing-Problems haben wir das Profil erneut betrachtet und eine weitere Optimierungsm√∂glichkeit gefunden, die einen erheblichen Teil des Overheads reduzieren w√ºrde.

Beim Erstellen eines Heap-Snapshots versucht V8 f√ºr jede Funktion im Heap, deren Startposition in Form eines Paars aus Zeilen- und Spaltennummern aufzuzeichnen. Diese Informationen k√∂nnen von den DevTools verwendet werden, um einen Link zum Quellcode der Funktion anzuzeigen. W√§hrend der √ºblichen Kompilierung speichert V8 jedoch nur die Startposition jeder Funktion als linearen Offset vom Beginn des Skripts. Um die Zeilen- und Spaltennummern basierend auf dem linearen Offset zu berechnen, muss V8 das gesamte Skript durchlaufen und dort die Zeilenumbr√ºche aufzeichnen. Diese Berechnung erweist sich als sehr teuer.

Normalerweise, nachdem V8 die Offsets der Zeilenumbr√ºche in einem Skript berechnet hat, speichert es diese in einem neu zugewiesenen Array, das dem Skript zugeordnet ist. Leider kann die Snapshot-Implementierung den Heap beim Durchlaufen nicht ver√§ndern, sodass die neu berechneten Zeileninformationen nicht zwischengespeichert werden k√∂nnen.

Die L√∂sung? Vor der Erstellung des Heap-Snapshots durchlaufen wir jetzt alle Skripte im V8-Kontext, um die Offsets der Zeilenumbr√ºche zu berechnen und zu speichern. Da dies nicht geschieht, wenn wir den Heap f√ºr die Erstellung des Heap-Snapshots durchlaufen, ist es dennoch m√∂glich, den Heap zu ver√§ndern und die Startpositionen der Quellzeilen als Cache abzulegen.

[Der Fix f√ºr das Caching der Zeilenumbruch-Offsets](https://chromium-review.googlesource.com/c/v8/v8/+/4538766) wurde ebenfalls in V8 integriert.

## Haben wir es schnell gemacht?

Nachdem beide Fixes aktiviert wurden, haben wir das Profil erneut betrachtet. Beide unserer Fixes wirken sich nur auf die Snapshot-Erstellungszeit aus, sodass die Zeit f√ºr die Snapshot-Serialisierung erwartungsgem√§√ü nicht beeinflusst wurde.

Beim Arbeiten mit einem JS-Programm, das‚Ä¶

- Entwicklungs-JS enth√§lt, ist die Erstellungszeit **50 % schneller** üëç
- Produktions-JS enth√§lt, ist die Erstellungszeit **90 % schneller** üòÆ

Warum gab es einen drastischen Unterschied zwischen Produktions- und Entwicklungs-Code? Der Produktions-Code wird durch B√ºndelung und Minifizierung optimiert, sodass es weniger JS-Dateien gibt und diese Dateien tendenziell gro√ü sind. Es dauert l√§nger, die Positionen der Quellzeilen f√ºr diese gro√üen Dateien zu berechnen, daher profitieren sie am meisten davon, wenn wir die Quellpositionen zwischenspeichern und die Berechnungen nicht wiederholen m√ºssen.

Die Optimierungen wurden sowohl in Windows- als auch in Linux-Zielumgebungen validiert.

F√ºr das urspr√ºnglich besonders herausfordernde Problem, das die Ingenieure von Bloomberg hatten, wurde die Gesamtdurchlaufzeit zur Erfassung eines 100-MB-Snapshots von schmerzhaften 10 Minuten auf sehr angenehme 6 Sekunden reduziert. Das entspricht einem **100-fachen Gewinn!** üî•

Die Optimierungen sind generische Gewinne, die unserer Ansicht nach weitreichend anwendbar sind f√ºr jeden, der Speicher-Debugging mit V8, Node.js und Chromium durchf√ºhrt. Diese Verbesserungen wurden in V8 v11.5.130 eingef√ºhrt, was bedeutet, dass sie in Chromium 115.0.5576.0 zu finden sind. Wir freuen uns darauf, dass Node.js diese Optimierungen in der n√§chsten semver-major-Version √ºbernimmt.

## Was steht als N√§chstes an?

Zun√§chst w√§re es sinnvoll, wenn Node.js die neue `--profile-heap-snapshot`-Flag in `NODE_OPTIONS` akzeptiert. In einigen Anwendungsf√§llen k√∂nnen Benutzer die Kommandozeilenoptionen, die direkt an Node.js √ºbergeben werden, nicht kontrollieren und m√ºssen sie √ºber die Umgebungsvariable `NODE_OPTIONS` konfigurieren. Heute filtert Node.js die in der Umgebungsvariable eingestellten V8-Kommandozeilenoptionen und erlaubt nur eine bekannte Teilmenge, was es schwieriger machen k√∂nnte, neue V8-Flags in Node.js zu testen, wie es in unserem Fall passiert ist.

Die Genauigkeit der Informationen in Snapshots kann weiter verbessert werden. Heute werden die Quellcode-Zeileninformationen jedes Skripts in einer Darstellung direkt im V8-Heap gespeichert. Und das ist ein Problem, weil wir den Heap pr√§zise messen m√∂chten, ohne dass der Leistungs√ºberwachungsoverhead das zu beobachtende Subjekt beeinflusst. Idealerweise w√ºrden wir den Cache der Zeileninformationen au√üerhalb des V8-Heaps speichern, um die Informationen des Heap-Snapshots genauer zu machen.

Schlie√ülich, jetzt, da wir die Generierungsphase verbessert haben, sind die gr√∂√üten Kosten nun in der Serialisierungsphase. Weitere Analysen k√∂nnten neue Optimierungsm√∂glichkeiten in der Serialisierung aufdecken.

## Credits

Dies war m√∂glich dank der Arbeit der Ingenieure von [Igalia](https://www.igalia.com/) und [Bloomberg](https://techatbloomberg.com/).
