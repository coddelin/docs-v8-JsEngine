---
title: 'Acelerando snapshots do heap do V8'
description: 'Esta postagem sobre snapshots do heap do V8 apresenta alguns problemas de desempenho encontrados por engenheiros da Bloomberg e como os corrigimos para tornar a an√°lise de mem√≥ria do JavaScript mais r√°pida do que nunca.'
author: 'Jose Dapena Paz'
date: 2023-07-27
tags:
 - mem√≥ria
 - ferramentas
---
*Esta postagem no blog foi escrita por Jos√© Dapena Paz (Igalia), com contribui√ß√µes de Jason Williams (Bloomberg), Ashley Claymore (Bloomberg), Rob Palmer (Bloomberg), Joyee Cheung (Igalia) e Shu-yu Guo (Google).*

Nesta postagem sobre snapshots do heap do V8, falarei sobre alguns problemas de desempenho encontrados por engenheiros da Bloomberg e como os corrigimos para tornar a an√°lise de mem√≥ria do JavaScript mais r√°pida do que nunca.

## O problema

Engenheiros da Bloomberg estavam trabalhando no diagn√≥stico de um vazamento de mem√≥ria em uma aplica√ß√£o JavaScript. A aplica√ß√£o estava falhando com erros de *Out-Of-Memory*. Para a aplica√ß√£o testada, o limite do heap do V8 foi configurado para cerca de 1400 MB. Normalmente, o coletor de lixo do V8 deveria ser capaz de manter o uso do heap abaixo desse limite, ent√£o as falhas indicavam que provavelmente havia um vazamento.

<!--truncate-->
Uma t√©cnica comum para depurar um cen√°rio de vazamento de mem√≥ria rotineiro como este √© capturar primeiro um snapshot do heap, carreg√°-lo na aba ‚ÄúMemory‚Äù do DevTools e descobrir o que est√° consumindo mais mem√≥ria inspecionando os v√°rios resumos e atributos de objetos. Na interface do DevTools, o snapshot do heap pode ser tirado na aba ‚ÄúMemory‚Äù. Para aplica√ß√µes Node.js, o snapshot do heap [pode ser acionado programaticamente](https://nodejs.org/en/docs/guides/diagnostics/memory/using-heap-snapshot) usando esta API:

```js
require('v8').writeHeapSnapshot();
```

Eles queriam capturar v√°rios snapshots em diferentes pontos da vida da aplica√ß√£o, para que o visualizador de mem√≥ria do DevTools pudesse ser usado para mostrar a diferen√ßa entre os heaps em momentos diferentes. O problema era que capturar um √∫nico snapshot de tamanho completo (500 MB) estava levando **mais de 30 minutos**!

Era essa lentid√£o no fluxo de trabalho de an√°lise de mem√≥ria que precis√°vamos resolver.

## Restringindo o problema

Ent√£o, engenheiros da Bloomberg come√ßaram a investigar o problema usando alguns par√¢metros do V8. Conforme descrito [nesta postagem](https://blogs.igalia.com/dape/2023/05/18/javascript-memory-profiling-with-heap-snapshot/), Node.js e V8 t√™m alguns bons par√¢metros de linha de comando que podem ajudar com isso. Essas op√ß√µes foram usadas para criar os snapshots do heap, simplificar a reprodu√ß√£o e melhorar a observabilidade:

- `--max-old-space-size=100`: Isso limita o heap a 100 megabytes e ajuda a reproduzir o problema muito mais rapidamente.
- `--heapsnapshot-near-heap-limit=10`: Este √© um par√¢metro de linha de comando espec√≠fico do Node.js que instrui o Node.js a gerar um snapshot toda vez que estiver pr√≥ximo de ficar sem mem√≥ria. Ele est√° configurado para gerar at√© 10 snapshots no total. Isso evita o desgaste em que o programa com falta de mem√≥ria passa muito tempo produzindo mais snapshots do que o necess√°rio.
- `--enable-etw-stack-walking`: Isso permite que ferramentas como ETW, WPA e xperf vejam a pilha JS que foi chamada no V8. (dispon√≠vel no Node.js v20+)
- `--interpreted-frames-native-stack`: Esse flag √© usado em combina√ß√£o com ferramentas como ETW, WPA e xperf para ver a pilha nativa ao fazer profiling. (dispon√≠vel no Node.js v20+)

Quando o tamanho do heap do V8 est√° se aproximando do limite, o V8 for√ßa uma coleta de lixo para reduzir o uso de mem√≥ria. Ele tamb√©m notifica o incorporador sobre isso. O flag `--heapsnapshot-near-heap-limit` no Node.js gera um novo snapshot do heap ap√≥s a notifica√ß√£o. No caso de teste, o uso da mem√≥ria diminui, mas, ap√≥s v√°rias itera√ß√µes, a coleta de lixo acaba n√£o conseguindo liberar espa√ßo suficiente e, assim, a aplica√ß√£o √© encerrada com um erro de *Out-Of-Memory*.

Eles fizeram grava√ß√µes utilizando o Windows Performance Analyzer (veja abaixo) a fim de restringir o problema. Isso revelou que a maior parte do tempo da CPU estava sendo gasta dentro do V8 Heap Explorer. Especificamente, levaram cerca de 30 minutos apenas para percorrer o heap, visitar cada n√≥ e coletar o nome. Isso n√£o parecia fazer muito sentido ‚Äî por que registrar o nome de cada propriedade levaria tanto tempo?

Foi ent√£o que me pediram para dar uma olhada.

## Quantificando o problema

O primeiro passo foi adicionar suporte no V8 para entender melhor onde o tempo √© gasto durante a captura de snapshots do heap. O pr√≥prio processo de captura est√° dividido em duas fases: gera√ß√£o e serializa√ß√£o. N√≥s enviamos [este patch](https://chromium-review.googlesource.com/c/v8/v8/+/4428810) para o upstream para introduzir um novo flag de linha de comando `--profile_heap_snapshot` ao V8, que permite o registro dos tempos de gera√ß√£o e serializa√ß√£o.

Usando esse flag, aprendemos algumas coisas interessantes!

Primeiro, pudemos observar a quantidade exata de tempo que o V8 estava gastando para gerar cada instant√¢neo. Em nosso caso de teste reduzido, o primeiro levou 5 minutos, o segundo levou 8 minutos e cada instant√¢neo subsequente continuava demorando mais e mais. Quase todo esse tempo foi gasto na fase de gera√ß√£o.

Isso tamb√©m nos permitiu quantificar o tempo gasto na gera√ß√£o de instant√¢neos com uma sobrecarga trivial, o que nos ajudou a isolar e identificar lentid√µes semelhantes em outros aplicativos JavaScript amplamente utilizados - em particular, o ESLint no TypeScript. Assim, sabemos que o problema n√£o era espec√≠fico do aplicativo.

Al√©m disso, descobrimos que o problema ocorria tanto no Windows quanto no Linux. O problema tamb√©m n√£o era espec√≠fico da plataforma.

## Primeira otimiza√ß√£o: melhoria no hash do `StringsStorage`

Para identificar o que estava causando o atraso excessivo, eu analisei o script com falha usando o [Windows Performance Toolkit](https://learn.microsoft.com/en-us/windows-hardware/test/wpt/).

Quando abri a grava√ß√£o com o [Windows Performance Analyzer](https://learn.microsoft.com/en-us/windows-hardware/test/wpt/windows-performance-analyzer), foi isso que encontrei:

![](/_img/speeding-up-v8-heap-snapshots/wpa-1.png)


Um ter√ßo das amostras foi gasto no `v8::internal::StringsStorage::GetEntry`:

```cpp
181 base::HashMap::Entry* StringsStorage::GetEntry(const char* str, int len) {
182   uint32_t hash = ComputeStringHash(str, len);
183   return names_.LookupOrInsert(const_cast<char*>(str), hash);
184 }
```

Como isso foi executado com uma vers√£o release, as informa√ß√µes das chamadas de fun√ß√£o embutidas foram integradas em `StringsStorage::GetEntry()`. Para descobrir exatamente quanto tempo as chamadas de fun√ß√µes embutidas estavam levando, adicionei a coluna "Source Line Number" √† an√°lise detalhada e descobri que a maior parte do tempo era gasto na linha 182, que era uma chamada para `ComputeStringHash()`:

![](/_img/speeding-up-v8-heap-snapshots/wpa-2.png)

Portanto, mais de 30% do tempo de gera√ß√£o do instant√¢neo foi gasto no `ComputeStringHash()`, mas por qu√™?

Vamos primeiro falar sobre o `StringsStorage`. Seu prop√≥sito √© armazenar uma c√≥pia √∫nica de todas as strings que ser√£o usadas no instant√¢neo de heap. Para acesso r√°pido e evitar duplicatas, esta classe utiliza um hashmap baseado em um array, onde colis√µes s√£o tratadas armazenando elementos na pr√≥xima posi√ß√£o livre no array.

Comecei a suspeitar que o problema poderia ser causado por colis√µes, o que poderia levar a longas buscas no array. Ent√£o adicionei logs exaustivos para ver as chaves hash geradas e, na inser√ß√£o, verificar qu√£o longe estava da posi√ß√£o esperada calculada a partir da chave hash para a posi√ß√£o real onde a entrada terminou devido a colis√µes.

Nos logs, as coisas estavam‚Ä¶ fora do comum: o deslocamento de muitos itens era superior a 20, e no pior caso, na ordem de milhares!

Parte do problema era causada por strings num√©ricas ‚Äî especialmente strings para uma ampla faixa de n√∫meros consecutivos. O algoritmo de chave hash tinha duas implementa√ß√µes, uma para strings num√©ricas e outra para outras strings. Enquanto a fun√ß√£o de hash para strings era bastante cl√°ssica, a implementa√ß√£o para strings num√©ricas basicamente retornava o valor do n√∫mero prefixado pelo n√∫mero de d√≠gitos:

```cpp
int32_t OriginalHash(const std::string& numeric_string) {
  int kValueBits = 24;

  int32_t mask = (1 << kValueBits) - 1; /* 0xffffff */
  return (numeric_string.length() << kValueBits) | (numeric_string & mask);
}
```

| `x` | `OriginalHash(x)` |
| --: | ----------------: |
|   0 |       `0x1000000` |
|   1 |       `0x1000001` |
|   2 |       `0x1000002` |
|   3 |       `0x1000003` |
|  10 |       `0x200000a` |
|  11 |       `0x200000b` |
| 100 |       `0x3000064` |

Essa fun√ß√£o era problem√°tica. Alguns exemplos de problemas com essa fun√ß√£o de hash:

- Uma vez que inser√≠amos uma string cuja chave hash era um n√∫mero pequeno, enfrent√°vamos colis√µes ao tentar armazenar outro n√∫mero nessa localiza√ß√£o, e haveria colis√µes semelhantes se tent√°ssemos armazenar n√∫meros subsequentes consecutivamente.
- Ou pior ainda: se j√° havia muitos n√∫meros consecutivos armazenados no mapa, e quer√≠amos inserir uma string cuja chave hash estava nessa faixa, t√≠nhamos que mover a entrada por todas as localiza√ß√µes ocupadas para encontrar uma livre.

O que fiz para corrigir isso? Como o problema vem principalmente de n√∫meros representados como strings que ca√≠am em posi√ß√µes consecutivas, modifiquei a fun√ß√£o de hash para que rotacion√°ssemos o valor hash resultante 2 bits para a esquerda.

```cpp
int32_t NewHash(const std::string& numeric_string) {
  return OriginalHash(numeric_string) << 2;
}
```

| `x` | `OriginalHash(x)` | `NewHash(x)` |
| --: | ----------------: | -----------: |
|   0 |       `0x1000000` |  `0x4000000` |
|   1 |       `0x1000001` |  `0x4000004` |
|   2 |       `0x1000002` |  `0x4000008` |
|   3 |       `0x1000003` |  `0x400000c` |
|  10 |       `0x200000a` |  `0x8000028` |
|  11 |       `0x200000b` |  `0x800002c` |
| 100 |       `0x3000064` |  `0xc000190` |

Ent√£o, para cada par de n√∫meros consecutivos, introduz√≠amos 3 posi√ß√µes livres entre eles. Essa modifica√ß√£o foi escolhida porque testes emp√≠ricos em v√°rios conjuntos de trabalho mostraram que ela funcionava melhor para minimizar colis√µes.

[Esta corre√ß√£o de hashing](https://chromium-review.googlesource.com/c/v8/v8/+/4428811) foi implementada no V8.

## Segunda otimiza√ß√£o: cache de posi√ß√µes de origem

Ap√≥s corrigir o hashing, reanalisamos e encontramos uma nova oportunidade de otimiza√ß√£o que reduziria uma parte significativa da sobrecarga.

Ao gerar um snapshot do heap, para cada fun√ß√£o no heap, o V8 tenta registrar sua posi√ß√£o inicial em um par de n√∫meros de linha e coluna. Essas informa√ß√µes podem ser usadas pelo DevTools para exibir um link para o c√≥digo fonte da fun√ß√£o. Durante a compila√ß√£o usual, no entanto, o V8 apenas armazena a posi√ß√£o inicial de cada fun√ß√£o na forma de um deslocamento linear a partir do in√≠cio do script. Para calcular os n√∫meros de linha e coluna com base no deslocamento linear, o V8 precisa percorrer todo o script e registrar onde est√£o as quebras de linha. Esse c√°lculo acaba sendo muito oneroso.

Normalmente, ap√≥s o V8 terminar de calcular os deslocamentos das quebras de linha em um script, ele os armazena em um array alocado recentemente anexado ao script. Infelizmente, a implementa√ß√£o do snapshot n√£o pode modificar o heap ao percorr√™-lo, ent√£o as informa√ß√µes de linha calculadas recentemente n√£o podem ser armazenadas em cache.

A solu√ß√£o? Antes de gerar o snapshot do heap, agora iteramos por todos os scripts no contexto do V8 para calcular e armazenar em cache os deslocamentos das quebras de linha. Como isso n√£o √© feito ao percorrer o heap para a gera√ß√£o do snapshot, ainda √© poss√≠vel modificar o heap e armazenar as posi√ß√µes da linha de origem como um cache.

[A corre√ß√£o para o armazenamento em cache de deslocamentos de quebra de linha](https://chromium-review.googlesource.com/c/v8/v8/+/4538766) tamb√©m foi implementada no V8.

## Conseguimos torn√°-lo r√°pido?

Ap√≥s ativar ambas as corre√ß√µes, realizamos um novo perfilamento. Nossas corre√ß√µes afetam apenas o tempo de gera√ß√£o de snapshot, ent√£o, como esperado, os tempos de serializa√ß√£o de snapshot n√£o foram afetados.

Ao operar em um programa JS contendo...

- JS em desenvolvimento, o tempo de gera√ß√£o √© **50% mais r√°pido** üëç
- JS em produ√ß√£o, o tempo de gera√ß√£o √© **90% mais r√°pido** üòÆ

Por que houve uma diferen√ßa t√£o grande entre o c√≥digo de produ√ß√£o e o de desenvolvimento? O c√≥digo de produ√ß√£o √© otimizado usando empacotamento e minifica√ß√£o, portanto h√° menos arquivos JS, e esses arquivos tendem a ser grandes. Leva mais tempo para calcular as posi√ß√µes das linhas de origem para esses arquivos grandes, ent√£o eles se beneficiam mais quando podemos armazenar em cache a posi√ß√£o de origem e evitar c√°lculos repetidos.

As otimiza√ß√µes foram validadas nos ambientes alvo Windows e Linux.

Para o problema particularmente desafiador enfrentado originalmente pelos engenheiros da Bloomberg, o tempo total de ponta a ponta para capturar um snapshot de 100MB foi reduzido de 10 minutos dolorosos para agrad√°veis 6 segundos. Isso representa **uma melhoria de 100√ó!** üî•

As otimiza√ß√µes s√£o ganhos gen√©ricos que esperamos ser amplamente aplic√°veis a qualquer pessoa realizando depura√ß√£o de mem√≥ria no V8, Node.js e Chromium. Esses ganhos foram lan√ßados no V8 v11.5.130, o que significa que est√£o presentes no Chromium 115.0.5576.0. Estamos ansiosos para que o Node.js adote essas otimiza√ß√µes na pr√≥xima vers√£o sem√¢ntico-major.

## O que vem a seguir?

Primeiro, seria √∫til para o Node.js aceitar a nova flag `--profile-heap-snapshot` em `NODE_OPTIONS`. Em alguns casos de uso, os usu√°rios n√£o podem controlar diretamente as op√ß√µes de linha de comando passadas para o Node.js e precisam configur√°-las por meio da vari√°vel de ambiente `NODE_OPTIONS`. Hoje, o Node.js filtra op√ß√µes de linha de comando do V8 definidas na vari√°vel de ambiente, permitindo apenas um subconjunto conhecido, o que pode dificultar o teste de novas flags do V8 no Node.js, como aconteceu no nosso caso.

A precis√£o das informa√ß√µes nos snapshots pode ser ainda mais aprimorada. Hoje, cada linha do c√≥digo fonte do script √© armazenada em uma representa√ß√£o no pr√≥prio heap do V8. E isso √© um problema porque queremos medir o heap com precis√£o sem que a sobrecarga de medi√ß√£o de desempenho afete o objeto que estamos observando. Idealmente, armazenar√≠amos o cache das informa√ß√µes de linha fora do heap do V8 para tornar as informa√ß√µes do snapshot do heap mais precisas.

Por fim, agora que aprimoramos a fase de gera√ß√£o, o maior custo agora √© a fase de serializa√ß√£o. Uma an√°lise adicional pode revelar novas oportunidades de otimiza√ß√£o na serializa√ß√£o.

## Cr√©ditos

Isso foi poss√≠vel gra√ßas ao trabalho dos engenheiros da [Igalia](https://www.igalia.com/) e da [Bloomberg](https://techatbloomberg.com/).
