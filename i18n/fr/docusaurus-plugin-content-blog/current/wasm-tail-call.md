---
title: "Appels en queue dans WebAssembly"
author: "Thibaud Michaud, Thomas Lively"
date: 2023-04-06
tags: 
  - WebAssembly
description: "Ce document explique la proposition concernant les appels en queue dans WebAssembly et la d√©montre avec quelques exemples."
tweet: "1644077795059044353"
---
Nous int√©grons les appels en queue de WebAssembly dans V8 v11.2 ! Dans cet article, nous donnons un aper√ßu de cette proposition, pr√©sentons un cas d‚Äôutilisation int√©ressant pour les coroutines C++ avec Emscripten, et montrons comment V8 g√®re les appels en queue en interne.

## Qu'est-ce que l'optimisation des appels en queue ?

Un appel est dit √™tre en position de queue si c'est la derni√®re instruction ex√©cut√©e avant de retourner de la fonction actuelle. Les compilateurs peuvent optimiser ces appels en supprimant la pile de l'appelant et en rempla√ßant l‚Äôappel par un saut.

Cela est particuli√®rement utile pour les fonctions r√©cursives. Par exemple, prenez cette fonction C qui additionne les √©l√©ments d'une liste cha√Æn√©e :

```c
int sum(List* list, int acc) {
  if (list == nullptr) return acc;
  return sum(list->next, acc + list->val);
}
```

Avec un appel classique, cela consomme un espace de pile de ùí™(n) : chaque √©l√©ment de la liste ajoute un nouveau cadre √† la pile d'appels. Avec une liste assez longue, cela peut rapidement provoquer un d√©bordement de pile. En rempla√ßant l'appel par un saut, l'optimisation des appels en queue transforme efficacement cette fonction r√©cursive en une boucle utilisant un espace de pile de ùí™(1) :

<!--truncate-->
```c
int sum(List* list, int acc) {
  while (list != nullptr) {
    acc = acc + list->val;
    list = list->next;
  }
  return acc;
}
```

Cette optimisation est particuli√®rement importante pour les langages fonctionnels. Ils reposent fortement sur des fonctions r√©cursives, et les langages purs comme Haskell ne fournissent m√™me pas de structures de contr√¥le de boucle. Toute sorte d'it√©ration personnalis√©e utilise typiquement une mani√®re ou une autre la r√©cursivit√©. Sans optimisation des appels en queue, cela provoquerait tr√®s rapidement un d√©bordement de pile pour tout programme non trivial.

### La proposition des appels en queue dans WebAssembly

Il existe deux fa√ßons d'appeler une fonction dans la version MVP de Wasm : `call` et `call_indirect`. La proposition ajoutant les appels en queue dans WebAssembly introduit leurs √©quivalents pour les appels en queue : `return_call` et `return_call_indirect`. Cela signifie que la cha√Æne d'outils est responsable de la r√©alisation effective de l'optimisation des appels en queue et d'√©mettre le type d'appel appropri√©, ce qui lui donne un meilleur contr√¥le sur les performances et l'utilisation de l'espace de pile.

Examinons une fonction Fibonacci r√©cursive. Le code bytecode de Wasm est inclus ici dans le format textuel pour √™tre complet, mais vous pouvez le trouver en C++ dans la section suivante :

```wasm/4
(func $fib_rec (param $n i32) (param $a i32) (param $b i32) (result i32)
  (if (i32.eqz (local.get $n))
    (then (return (local.get $a)))
    (else
      (return_call $fib_rec
        (i32.sub (local.get $n) (i32.const 1))
        (local.get $b)
        (i32.add (local.get $a) (local.get $b))
      )
    )
  )
)

(func $fib (param $n i32) (result i32)
  (call $fib_rec (local.get $n) (i32.const 0) (i32.const 1))
)
```

√Ä tout moment, il n'y a qu'un seul cadre `fib_rec`, qui se d√©roule avant d'effectuer le prochain appel r√©cursif. Lorsque nous atteignons le cas de base, `fib_rec` retourne directement le r√©sultat `a` √† `fib`.

Une cons√©quence observable des appels en queue est (en plus d'un risque r√©duit de d√©bordement de pile) que les appelants en queue n'apparaissent pas dans les traces de pile. Ils n'apparaissent pas non plus dans la propri√©t√© de la pile d'une exception captur√©e ni dans la trace de pile des DevTools. Au moment o√π une exception est lev√©e ou que l'ex√©cution est mise en pause, les cadres des appelants en queue ont disparu et V8 ne peut pas les r√©cup√©rer.

## Utilisation des appels en queue avec Emscripten

Les langages fonctionnels d√©pendent souvent des appels en queue, mais il est √©galement possible de les utiliser en tant que programmeur C ou C++. Emscripten (et Clang, qu'Emscripten utilise) prend en charge l'attribut musttail qui indique au compilateur qu'un appel doit √™tre compil√© en un appel en queue. √Ä titre d'exemple, consid√©rez cette impl√©mentation r√©cursive d'une fonction Fibonacci qui calcule le `n`i√®me num√©ro de Fibonacci modulo 2^32 (car les entiers d√©bordent pour de grands `n`) :

```c
#include <stdio.h>

unsigned fib_rec(unsigned n, unsigned a, unsigned b) {
  if (n == 0) {
    return a;
  }
  return fib_rec(n - 1, b, a + b);
}

unsigned fib(unsigned n) {
  return fib_rec(n, 0, 1);
}

int main() {
  for (unsigned i = 0; i < 10; i++) {
    printf("fib(%d): %d\n", i, fib(i));
  }

  printf("fib(1000000): %d\n", fib(1000000));
}
```

Apr√®s compilation avec `emcc test.c -o test.js`, l'ex√©cution de ce programme dans Node.js d√©clenche une erreur de d√©bordement de pile. Nous pouvons r√©soudre cela en ajoutant `__attribute__((__musttail__))` au retour dans `fib_rec` et en ajoutant `-mtail-call` aux arguments de compilation. Maintenant, le module Wasm produit contient les nouvelles instructions d'appel en queue, donc nous devons passer `--experimental-wasm-return_call` √† Node.js, mais la pile ne d√©borde plus.

Voici un exemple utilisant √©galement la r√©cursivit√© mutuelle :

```c
#include <stdio.h>
#include <stdbool.h>

bool is_odd(unsigned n);
bool is_even(unsigned n);

bool is_odd(unsigned n) {
  if (n == 0) {
    return false;
  }
  __attribute__((__musttail__))
  return is_even(n - 1);
}

bool is_even(unsigned n) {
  if (n == 0) {
    return true;
  }
  __attribute__((__musttail__))
  return is_odd(n - 1);
}

int main() {
  printf("is_even(1000000): %d\n", is_even(1000000));
}
```

Notez que ces deux exemples sont suffisamment simples pour que, si nous compilons avec `-O2`, le compilateur puisse pr√©calculer la r√©ponse et √©viter d'√©puiser la pile m√™me sans appels tail, mais ce ne serait pas le cas avec un code plus complexe. Dans le code r√©el, l'attribut musttail peut √™tre utile pour √©crire des boucles d'interpr√©teur haute performance comme d√©crit dans [cet article de blog](https://blog.reverberate.org/2021/04/21/musttail-efficient-interpreters.html) par Josh Haberman.

En dehors de l'attribut `musttail`, le C++ d√©pend des appels tail pour une autre fonctionnalit√© : les coroutines C++20. La relation entre les appels tail et les coroutines C++20 est couverte en profondeur dans [cet article de blog](https://lewissbaker.github.io/2020/05/11/understanding_symmetric_transfer) par Lewis Baker, mais pour r√©sumer, il est possible d'utiliser des coroutines dans un mod√®le qui provoquerait subtilement un d√©bordement de pile m√™me si le code source ne semble pas poser probl√®me. Pour r√©soudre ce probl√®me, le comit√© C++ a ajout√© une exigence selon laquelle les compilateurs doivent impl√©menter le ‚Äútransfert sym√©trique‚Äù pour √©viter le d√©bordement de pile, ce qui, en pratique, signifie utiliser des appels tail en coulisses.

Lorsque les appels tail WebAssembly sont activ√©s, Clang impl√©mente le transfert sym√©trique d√©crit dans cet article de blog, mais lorsque les appels tail ne sont pas activ√©s, Clang compile silencieusement le code sans transfert sym√©trique, ce qui pourrait entra√Æner des d√©bordements de pile et n'est techniquement pas une impl√©mentation correcte du C++20 !

Pour voir la diff√©rence en action, utilisez Emscripten pour compiler le dernier exemple de l'article de blog mentionn√© ci-dessus et observez qu'il √©vite uniquement le d√©bordement de pile si les appels tail sont activ√©s. Notez qu'en raison d'un bogue r√©cemment corrig√©, cela ne fonctionne correctement que dans Emscripten 3.1.35 ou une version ult√©rieure.

## Appels tail dans V8

Comme nous l'avons vu plus t√¥t, il n'appartient pas au moteur de d√©tecter les appels en position tail. Cela devrait √™tre fait en amont par la cha√Æne d'outils. Ainsi, la seule t√¢che restante pour TurboFan (le compilateur optimis√© de V8) est de produire une s√©quence d'instructions appropri√©e bas√©e sur le type d'appel et la signature de la fonction cible. Pour notre exemple fibonacci vu pr√©c√©demment, la pile se pr√©senterait comme suit :

![Appel tail simple dans TurboFan](/_img/wasm-tail-calls/tail-calls.svg)

√Ä gauche, nous sommes dans `fib_rec` (en vert), appel√© par `fib` (en bleu) et √† point de faire un appel tail r√©cursif √† `fib_rec`. Tout d'abord, nous d√©s√©mpilons le cadre actuel en r√©initialisant le pointeur de cadre et le pointeur de pile. Le pointeur de cadre restaure simplement sa valeur pr√©c√©dente en la lisant depuis l'emplacement ‚ÄúCaller FP‚Äù. Le pointeur de pile se d√©place vers le haut du cadre parent, plus suffisamment d'espace pour tout param√®tre potentiel de pile et retour de pile pour le calque (0 dans ce cas, tout est pass√© par des registres). Les param√®tres sont plac√©s dans leurs registres pr√©vus conform√©ment √† la liaison de `fib_rec` (non visible dans le diagramme). Et enfin, nous commen√ßons √† ex√©cuter `fib_rec`, qui commence par cr√©er un nouveau cadre.

`fib_rec` d√©s√©mpile et r√©√©mpile lui-m√™me comme ceci jusqu'√† ce que `n == 0`, moment auquel il retourne `a` par registre √† `fib`.

C'est un cas simple o√π tous les param√®tres et valeurs de retour tiennent dans les registres, et l'appelant et le calqu√© ont la m√™me signature. En cas g√©n√©ral, nous pourrions devoir effectuer des manipulations complexes de la pile :

- Lire les param√®tres sortants depuis l'ancien cadre
- D√©placer les param√®tres dans le nouveau cadre
- Ajuster la taille du cadre en d√©pla√ßant l'adresse de retour vers le haut ou le bas, selon le nombre de param√®tres de pile dans le calqu√©

Toutes ces lectures et √©critures peuvent entrer en conflit les unes avec les autres, car nous r√©utilisons le m√™me espace de pile. C'est une diff√©rence cruciale avec un appel non-tail, qui pousserait simplement tous les param√®tres de pile et l'adresse de retour au-dessus de la pile.

![Appel tail complexe dans TurboFan](/_img/wasm-tail-calls/tail-calls-complex.svg)

TurboFan g√®re ces manipulations de pile et de registre avec le ‚Äúgap resolver‚Äù, un composant qui prend une liste de d√©placements qui devraient √™tre ex√©cut√©s en parall√®le de mani√®re s√©mantique et g√©n√®re la s√©quence appropri√©e de d√©placements pour r√©soudre les interf√©rences potentielles entre les sources et les destinations des d√©placements. Si les conflits sont acycliques, il s'agit simplement de r√©organiser les d√©placements de mani√®re √† ce que toutes les sources soient lues avant d'√™tre √©cras√©es. Pour les conflits cycliques (par exemple, si nous √©changeons deux param√®tres de pile), cela peut impliquer de d√©placer l'une des sources vers un registre temporaire ou un emplacement de pile temporaire pour briser le cycle.

Les appels en queue sont √©galement pris en charge dans Liftoff, notre compilateur de base. En fait, ils doivent √™tre pris en charge, sinon le code de base pourrait manquer d'espace de pile. Cependant, ils ne sont pas optimis√©s √† ce niveau¬†: Liftoff empile les param√®tres, l'adresse de retour et le pointeur de trame pour compl√©ter la trame comme s'il s'agissait d'un appel r√©gulier, puis d√©place tout vers le bas pour supprimer la trame de l'appelant¬†:

![Appels en queue dans Liftoff](/_img/wasm-tail-calls/tail-calls-liftoff.svg)

Avant de sauter √† la fonction cible, nous vidons √©galement la FP de l'appelant dans le registre FP pour restaurer sa valeur pr√©c√©dente, et permettre √† la fonction cible de l'empiler √† nouveau dans le prologue.

Cette strat√©gie ne n√©cessite pas que nous analysions et r√©solvions les conflits de d√©placement, ce qui rend la compilation plus rapide. Le code g√©n√©r√© est plus lent, mais [passe finalement √† un niveau sup√©rieur](/blog/wasm-dynamic-tiering) √† TurboFan si la fonction est suffisamment sollicit√©e.
