---
title: &apos;Acc√©l√©ration des instantan√©s de tas V8&apos;
description: &apos;Cet article sur les instantan√©s de tas V8 pr√©sente des probl√®mes de performance rencontr√©s par les ing√©nieurs de Bloomberg, et la fa√ßon dont nous les avons r√©solus pour rendre l&apos;analyse m√©moire JavaScript plus rapide que jamais.&apos;
author: &apos;Jos√© Dapena Paz&apos;
date: 2023-07-27
tags:
 - m√©moire
 - outils
---
*Cet article de blog a √©t√© r√©dig√© par Jos√© Dapena Paz (Igalia), avec les contributions de Jason Williams (Bloomberg), Ashley Claymore (Bloomberg), Rob Palmer (Bloomberg), Joyee Cheung (Igalia) et Shu-yu Guo (Google).*

Dans cet article sur les instantan√©s de tas V8, je vais parler de certains probl√®mes de performance rencontr√©s par les ing√©nieurs de Bloomberg et comment nous les avons r√©solus pour rendre l&apos;analyse m√©moire JavaScript plus rapide que jamais.

## Le probl√®me

Les ing√©nieurs de Bloomberg travaillaient sur le diagnostic d&apos;une fuite m√©moire dans une application JavaScript. Elle √©chouait avec des erreurs de type *Out-Of-Memory*. Pour l&apos;application test√©e, la limite du tas V8 √©tait configur√©e autour de 1400 Mo. Normalement, le ramasse-miettes de V8 devrait pouvoir maintenir l&apos;utilisation du tas en dessous de cette limite, de sorte que les √©checs indiquent probablement une fuite.

<!--truncate-->
Une technique courante pour d√©boguer un sc√©nario de fuite m√©moire de routine consiste √† capturer un instantan√© de tas, puis √† le charger dans l&apos;onglet "M√©moire" des DevTools et √† d√©couvrir ce qui utilise le plus de m√©moire en inspectant les diff√©rents r√©sum√©s et attributs d&apos;objets. Dans l&apos;interface utilisateur de DevTools, l&apos;instantan√© de tas peut √™tre pris dans l&apos;onglet "M√©moire". Pour les applications Node.js, l&apos;instantan√© de tas [peut √™tre d√©clench√© de mani√®re programmatique](https://nodejs.org/en/docs/guides/diagnostics/memory/using-heap-snapshot) en utilisant cette API:

```js
require(&apos;v8&apos;).writeHeapSnapshot();
```

Ils voulaient capturer plusieurs instantan√©s √† diff√©rents moments de la vie de l&apos;application, afin que le visualiseur de m√©moire de DevTools puisse √™tre utilis√© pour montrer la diff√©rence entre les tas √† diff√©rents moments. Le probl√®me √©tait que capturer un seul instantan√© de taille compl√®te (500 Mo) prenait **plus de 30 minutes**!

C&apos;est cette lenteur dans le flux de travail d&apos;analyse m√©moire que nous devions r√©soudre.

## R√©duire le probl√®me

Ensuite, les ing√©nieurs de Bloomberg ont commenc√© √† enqu√™ter sur le probl√®me en utilisant certains param√®tres de V8. Comme d√©crit dans [cet article](https://blogs.igalia.com/dape/2023/05/18/javascript-memory-profiling-with-heap-snapshot/), Node.js et V8 ont quelques param√®tres de ligne de commande utiles √† cet effet. Ces options ont √©t√© utilis√©es pour cr√©er les instantan√©s de tas, simplifier la reproduction et am√©liorer l&apos;observabilit√© :

- `--max-old-space-size=100`: Cela limite le tas √† 100 m√©gaoctets et aide √† reproduire le probl√®me beaucoup plus rapidement.
- `--heapsnapshot-near-heap-limit=10`: Il s&apos;agit d&apos;un param√®tre de ligne de commande sp√©cifique √† Node.js qui indique √† Node.js de g√©n√©rer un instantan√© chaque fois qu&apos;il approche de la limite de m√©moire. Il est configur√© pour g√©n√©rer jusqu&apos;√† 10 instantan√©s au total. Cela √©vite la situation o√π le programme √† court de m√©moire passe beaucoup de temps √† produire plus d&apos;instantan√©s que n√©cessaire.
- `--enable-etw-stack-walking`: Cela permet √† des outils tels que ETW, WPA et xperf de voir la pile JS appel√©e dans V8. (disponible dans Node.js v20+)
- `--interpreted-frames-native-stack`: Ce drapeau est utilis√© en combinaison avec des outils comme ETW, WPA et xperf pour voir la pile native lors du profilage. (disponible dans Node.js v20+).

Lorsque la taille du tas V8 approche de sa limite, V8 force un ramassage de m√©moire pour r√©duire l&apos;utilisation. Il informe √©galement l&apos;int√©grateur √† ce sujet. Le drapeau `--heapsnapshot-near-heap-limit` dans Node.js g√©n√®re un nouvel instantan√© de tas apr√®s notification. Dans le cas de test, l&apos;utilisation de la m√©moire diminue, mais, apr√®s plusieurs it√©rations, le ramassage de m√©moire ne peut finalement pas lib√©rer suffisamment d&apos;espace et l&apos;application est alors arr√™t√©e avec une erreur *Out-Of-Memory*.

Ils ont effectu√© des enregistrements en utilisant Windows Performance Analyzer (voir ci-dessous) afin de r√©duire le probl√®me. Cela a r√©v√©l√© que la majeure partie du temps CPU √©tait pass√©e dans l&apos;explorateur de tas V8. Plus pr√©cis√©ment, cela prenait environ 30 minutes juste pour parcourir le tas, visiter chaque n≈ìud et collecter le nom. Cela ne semblait pas avoir de sens ‚Äî pourquoi enregistrer le nom de chaque propri√©t√© prendrait-il autant de temps ?

C&apos;est √† ce moment-l√† qu&apos;on m&apos;a demand√© d&apos;examiner le probl√®me.

## Quantifier le probl√®me

La premi√®re √©tape consistait √† ajouter un support dans V8 pour mieux comprendre o√π le temps est consacr√© lors de la capture des instantan√©s de tas. Le processus de capture lui-m√™me est divis√© en deux phases : g√©n√©ration, puis s√©rialisation. Nous avons introduit [ce patch](https://chromium-review.googlesource.com/c/v8/v8/+/4428810) en amont pour ajouter un nouveau drapeau de ligne de commande `--profile_heap_snapshot` √† V8, qui permet de consigner les temps de g√©n√©ration et de s√©rialisation.

Avec ce drapeau, nous avons appris des choses int√©ressantes !

Tout d'abord, nous avons pu observer la dur√©e pr√©cise que V8 consacrait √† la g√©n√©ration de chaque instantan√©. Dans notre cas de test r√©duit, le premier a pris 5 minutes, le deuxi√®me a pris 8 minutes, et chaque instantan√© suivant continuait de prendre de plus en plus de temps. Presque tout ce temps √©tait consacr√© √† la phase de g√©n√©ration.

Cela nous a √©galement permis de quantifier le temps consacr√© √† la g√©n√©ration d'instantan√©s avec une surcharge triviale, ce qui nous a aid√© √† isoler et identifier des ralentissements similaires dans d'autres applications JavaScript largement utilis√©es - en particulier, ESLint sur TypeScript. Nous savons donc que le probl√®me n'√©tait pas sp√©cifique √† l'application.

De plus, nous avons constat√© que le probl√®me se produisait √† la fois sur Windows et Linux. Le probl√®me n'√©tait donc pas sp√©cifique √† la plateforme.

## Premi√®re optimisation : am√©lioration du hachage de `StringsStorage`

Pour identifier ce qui causait le d√©lai excessif, j'ai profil√© le script d√©faillant en utilisant [Windows Performance Toolkit](https://learn.microsoft.com/en-us/windows-hardware/test/wpt/).

Lorsque j'ai ouvert l'enregistrement avec [Windows Performance Analyzer](https://learn.microsoft.com/en-us/windows-hardware/test/wpt/windows-performance-analyzer), voici ce que j'ai trouv√© :

![](/_img/speeding-up-v8-heap-snapshots/wpa-1.png)


Un tiers des √©chantillons √©tait consacr√© √† `v8::internal::StringsStorage::GetEntry` :

```cpp
181 base::HashMap::Entry* StringsStorage::GetEntry(const char* str, int len) {
182   uint32_t hash = ComputeStringHash(str, len);
183   return names_.LookupOrInsert(const_cast<char*>(str), hash);
184 }
```

√âtant donn√© que cela a √©t√© ex√©cut√© avec une version de build release, les informations des appels de fonctions inline ont √©t√© regroup√©es dans `StringsStorage::GetEntry()`. Pour d√©terminer exactement combien de temps prenaient les appels de fonction inline, j'ai ajout√© la colonne "Num√©ro de ligne source" √† la r√©partition et constat√© que la majeure partie du temps √©tait consacr√©e √† la ligne 182, qui √©tait un appel √† `ComputeStringHash()` :

![](/_img/speeding-up-v8-heap-snapshots/wpa-2.png)

Ainsi, plus de 30 % du temps de g√©n√©ration des instantan√©s √©tait consacr√© √† `ComputeStringHash()`, mais pourquoi ?

Parlons d'abord de `StringsStorage`. Son objectif est de stocker une copie unique de toutes les cha√Ænes qui seront utilis√©es dans l'instantan√© du tas. Pour un acc√®s rapide et √©viter les doublons, cette classe utilise une hashmap soutenue par un tableau, o√π les collisions sont g√©r√©es en stockant les √©l√©ments dans le prochain emplacement libre du tableau.

J'ai commenc√© √† soup√ßonner que le probl√®me pouvait √™tre caus√© par des collisions, ce qui pourrait entra√Æner de longues recherches dans le tableau. J'ai donc ajout√© des journaux exhaustifs pour voir les cl√©s de hachage g√©n√©r√©es et, lors de l'insertion, voir la distance entre la position attendue calcul√©e √† partir de la cl√© de hachage et la position r√©elle o√π l'entr√©e √©tait finalement plac√©e en raison des collisions.

Dans les journaux, les choses n'allaient pas bien : le d√©calage de nombreux √©l√©ments d√©passait 20, et dans le pire des cas, de l'ordre de milliers !

Une partie du probl√®me √©tait caus√©e par des cha√Ænes num√©riques ‚Äî en particulier des cha√Ænes repr√©sentant une large gamme de nombres cons√©cutifs. L'algorithme de cl√© de hachage poss√©dait deux impl√©mentations, une pour les cha√Ænes num√©riques et une autre pour les autres cha√Ænes. Alors que la fonction de hachage des cha√Ænes √©tait assez classique, l'impl√©mentation pour les cha√Ænes num√©riques renvoyait essentiellement la valeur du nombre pr√©c√©d√©e par le nombre de chiffres :

```cpp
int32_t OriginalHash(const std::string& numeric_string) {
  int kValueBits = 24;

  int32_t mask = (1 << kValueBits) - 1; /* 0xffffff */
  return (numeric_string.length() << kValueBits) | (numeric_string & mask);
}
```

| `x` | `OriginalHash(x)` |
| --: | ----------------: |
|   0 |       `0x1000000` |
|   1 |       `0x1000001` |
|   2 |       `0x1000002` |
|   3 |       `0x1000003` |
|  10 |       `0x200000a` |
|  11 |       `0x200000b` |
| 100 |       `0x3000064` |

Cette fonction posait probl√®me. Voici quelques exemples de probl√®mes li√©s √† cette fonction de hachage :

- Une fois qu'une cha√Æne dont la cl√© de hachage avait une valeur faible √©tait ins√©r√©e, nous rencontrions des collisions lorsque nous essayions de stocker un autre nombre √† cet emplacement, et des collisions similaires se produisaient si nous essayions de stocker des nombres cons√©cutifs.
- Ou pire encore : si un grand nombre de nombres cons√©cutifs √©taient d√©j√† stock√©s dans la carte et que nous voulions ins√©rer une cha√Æne dont la cl√© de hachage se trouvait dans cette plage, nous devions d√©placer l'entr√©e le long de tous les emplacements occup√©s pour trouver un emplacement libre.

Qu'ai-je fait pour r√©soudre cela ? Comme le probl√®me provient principalement des nombres repr√©sent√©s sous forme de cha√Ænes qui tomberaient dans des positions cons√©cutives, j'ai modifi√© la fonction de hachage afin de faire pivoter la valeur de hachage r√©sultante de 2 bits vers la gauche.

```cpp
int32_t NewHash(const std::string& numeric_string) {
  return OriginalHash(numeric_string) << 2;
}
```

| `x` | `OriginalHash(x)` | `NewHash(x)` |
| --: | ----------------: | -----------: |
|   0 |       `0x1000000` |  `0x4000000` |
|   1 |       `0x1000001` |  `0x4000004` |
|   2 |       `0x1000002` |  `0x4000008` |
|   3 |       `0x1000003` |  `0x400000c` |
|  10 |       `0x200000a` |  `0x8000028` |
|  11 |       `0x200000b` |  `0x800002c` |
| 100 |       `0x3000064` |  `0xc000190` |

Ainsi, pour chaque paire de nombres cons√©cutifs, nous introduisions 3 positions libres entre eux. Cette modification a √©t√© choisie car les tests empiriques sur plusieurs ensembles de travail ont montr√© qu'elle √©tait la meilleure pour minimiser les collisions.

[Cette correction de hachage](https://chromium-review.googlesource.com/c/v8/v8/+/4428811) a √©t√© int√©gr√©e dans V8.

## Deuxi√®me optimisation : mise en cache des positions de source

Apr√®s avoir corrig√© le hachage, nous avons reprofil√© et identifi√© une nouvelle opportunit√© d'optimisation qui permettrait de r√©duire une partie significative de la surcharge.

Lors de la g√©n√©ration d'une capture du tas, pour chaque fonction dans le tas, V8 tente d'enregistrer sa position de d√©but dans une paire de num√©ros de ligne et de colonne. Ces informations peuvent √™tre utilis√©es par les DevTools pour afficher un lien vers le code source de la fonction. Cependant, lors de la compilation normale, V8 stocke uniquement la position de d√©but de chaque fonction sous forme d'un d√©placement lin√©aire √† partir du d√©but du script. Pour calculer les num√©ros de ligne et de colonne √† partir du d√©placement lin√©aire, V8 doit traverser tout le script et enregistrer o√π se trouvent les sauts de ligne. Ce calcul s'av√®re tr√®s co√ªteux.

Normalement, apr√®s que V8 a fini de calculer les d√©calages des sauts de ligne dans un script, il les met en cache dans un tableau nouvellement allou√© attach√© au script. Malheureusement, l'impl√©mentation de la capture ne peut pas modifier le tas lorsqu'elle le parcourt, donc les informations de ligne nouvellement calcul√©es ne peuvent pas √™tre mises en cache.

La solution ? Avant de g√©n√©rer la capture du tas, nous parcourons maintenant tous les scripts du contexte V8 pour calculer et mettre en cache les d√©calages des sauts de ligne. √âtant donn√© que cela n'est pas fait lors de la travers√©e du tas pour la g√©n√©ration de la capture, il est toujours possible de modifier le tas et de stocker les positions des lignes sources en tant que cache.

[La correction pour la mise en cache des d√©calages des sauts de ligne](https://chromium-review.googlesource.com/c/v8/v8/+/4538766) a √©galement √©t√© int√©gr√©e dans V8.

## L'avons-nous rendu rapide ?

Apr√®s avoir activ√© les deux corrections, nous avons reprofil√©. Nos deux corrections n'affectent que le temps de g√©n√©ration de la capture, donc, comme pr√©vu, les temps de s√©rialisation des captures n'ont pas √©t√© modifi√©s.

Lors de l'ex√©cution sur un programme JS contenant‚Ä¶

- JS de d√©veloppement, le temps de g√©n√©ration est **50 % plus rapide** üëç
- JS de production, le temps de g√©n√©ration est **90 % plus rapide** üòÆ

Pourquoi y a-t-il une diff√©rence massive entre le code de production et de d√©veloppement ? Le code de production est optimis√© √† l'aide de l'empaquetage et de la minification, donc il y a moins de fichiers JS, et ces fichiers ont tendance √† √™tre grands. Il faut plus de temps pour calculer les positions des lignes sources pour ces fichiers volumineux, donc ils b√©n√©ficient le plus lorsque nous pouvons mettre en cache les positions sources et √©viter de r√©p√©ter les calculs.

Les optimisations ont √©t√© valid√©es sur les environnements cibles Windows et Linux.

Pour le probl√®me particuli√®rement difficile rencontr√© initialement par les ing√©nieurs de Bloomberg, le temps total de capture d'une capture de 100 Mo a √©t√© r√©duit d'un douloureux 10 minutes √† un tr√®s agr√©able 6 secondes. C'est **un gain de 100√ó** üî•

Les optimisations sont des gains g√©n√©riques que nous esp√©rons √™tre largement applicables √† quiconque effectue du d√©bogage m√©moire sur V8, Node.js et Chromium. Ces gains ont √©t√© int√©gr√©s dans V8 v11.5.130, ce qui signifie qu'ils apparaissent dans Chromium 115.0.5576.0. Nous esp√©rons que Node.js b√©n√©ficiera de ces optimisations dans la prochaine version majeure de semver.

## Et apr√®s ?

Premi√®rement, il serait utile que Node.js accepte le nouveau flag `--profile-heap-snapshot` dans `NODE_OPTIONS`. Dans certains cas d'utilisation, les utilisateurs ne peuvent pas contr√¥ler directement les options de ligne de commande pass√©es √† Node.js et doivent les configurer via la variable d'environnement `NODE_OPTIONS`. Aujourd'hui, Node.js filtre les options de ligne de commande V8 d√©finies dans la variable d'environnement et n'autorise qu'un sous-ensemble connu, ce qui pourrait rendre plus difficile le test des nouveaux flags V8 dans Node.js, comme cela s'est produit dans notre cas.

L'exactitude des informations dans les captures peut √™tre encore am√©lior√©e. Aujourd'hui, chaque ligne de code source de script est stock√©e dans une repr√©sentation dans le tas lui-m√™me de V8. Et c'est un probl√®me parce que nous voulons mesurer pr√©cis√©ment le tas sans que la surcharge de mesure des performances n'affecte le sujet que nous observons. Id√©alement, nous stockerions le cache des informations de lignes en dehors du tas de V8 afin de rendre les informations des captures du tas plus pr√©cises.

Enfin, maintenant que nous avons am√©lior√© la phase de g√©n√©ration, le co√ªt le plus important est d√©sormais la phase de s√©rialisation. Une analyse plus approfondie pourrait r√©v√©ler de nouvelles opportunit√©s d'optimisation dans la s√©rialisation.

## Remerciements

Cela a √©t√© rendu possible gr√¢ce au travail des ing√©nieurs de [Igalia](https://www.igalia.com/) et [Bloomberg](https://techatbloomberg.com/).
